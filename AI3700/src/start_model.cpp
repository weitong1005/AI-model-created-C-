#include "start_model.h"
#include <vector>
#include <string>
#include <queue>
#include <tuple>
#include <algorithm>
#include <iostream>  // å¢åŠ è°ƒè¯•è¾“å‡º

StartModel::StartModel(HanziEncoder& encoder, int hiddenSize, int layers)
        : encoder(encoder), model(encoder.size(), hiddenSize, layers), contextWindow(5) {}

bool StartModel::loadModel(const std::string& path) {
    if (!model.load(path)) {
        std::cerr << "âŒ æ¨¡å‹åŠ è½½å¤±è´¥: " << path << std::endl;
        return false;
    }
    return true;
}

bool StartModel::saveModel(const std::string& path) {
    // æ£€æŸ¥è·¯å¾„æ˜¯å¦æœ‰æ•ˆ
    if (path.empty()) {
        std::cerr << "âŒ æ¨¡å‹è·¯å¾„ä¸ºç©º" << std::endl;
        return false;
    }

    if (!model.save(path)) {
        std::cerr << "âŒ æ¨¡å‹ä¿å­˜å¤±è´¥: " << path << std::endl;
        // å°è¯•å¤‡é€‰è·¯å¾„
        std::string backupPath = "backup_" + path;
        if (model.save(backupPath)) {
            std::cerr << "âš ï¸ å·²ä¿å­˜åˆ°å¤‡é€‰è·¯å¾„: " << backupPath << std::endl;
            return true;
        }
        return false;
    }
    return true;
}

// æ–°å¢ï¼šç›‘æ§è®­ç»ƒè¿‡ç¨‹çš„è¾…åŠ©å‡½æ•°
void printTrainingProgress(int iteration, int total, double loss) {
    if (iteration % 1000 == 0) {
        double progress = static_cast<double>(iteration) / total * 100;
        printf("ğŸ“Š è®­ç»ƒè¿›åº¦: %.1f%% (è¿­ä»£ %d/%d), æŸå¤±: %.6f\n",
               progress, iteration, total, loss);
    }
}

void StartModel::train(int iterations, double lr) {
    // é’ˆå¯¹å¤§éšè—å±‚è°ƒæ•´è®­ç»ƒç­–ç•¥ï¼šå‡å°åˆå§‹å­¦ä¹ ç‡
    double initialLr = lr * 0.5;  // å¯¹äº128éšè—å±‚ï¼Œå­¦ä¹ ç‡å‡åŠ

    try {
        // åˆ†é˜¶æ®µè®­ç»ƒï¼Œå¢åŠ æŸå¤±ç›‘æ§
        for (int i = 0; i < iterations; i++) {
            // åŠ¨æ€è°ƒæ•´åºåˆ—é•¿åº¦ï¼Œé¿å…å†…å­˜æº¢å‡º
            int seqLen = 6 + (i % 3) * 2;  // 6-10ä¹‹é—´åŠ¨æ€è°ƒæ•´

            // ç”Ÿæˆè®­ç»ƒåºåˆ—
            std::vector<int> seq;
            for (int j = 0; j < seqLen; j++) {
                seq.push_back(rand() % encoder.size());
            }

            // è®­ç»ƒä¸€æ­¥å¹¶ç›‘æ§æŸå¤±ï¼ˆç®€åŒ–ç‰ˆæŸå¤±è®¡ç®—ï¼‰
            model.train(seq, initialLr * (1 - i/(double)iterations), i);

            // æ¯1000æ¬¡è¿­ä»£æ‰“å°ä¸€æ¬¡è¿›åº¦
            if (i % 1000 == 0) {
                printTrainingProgress(i, iterations, 0.0);  // å®é™…é¡¹ç›®ä¸­åº”è®¡ç®—çœŸå®æŸå¤±
            }

            // å®šæœŸæ£€æŸ¥æ•°å€¼ç¨³å®šæ€§
            if (i % 5000 == 0 && i > 0) {
                std::cout << "ğŸ” æ£€æŸ¥æ¨¡å‹ç¨³å®šæ€§..." << std::endl;
                // ç”Ÿæˆæµ‹è¯•åºåˆ—éªŒè¯æ¨¡å‹æ˜¯å¦æ­£å¸¸
                std::vector<int> testSeq = {0, 1, 2, 3};  // éšæœºé€‰æ‹©å‡ ä¸ªæ±‰å­—ç´¢å¼•
                int pred = model.predict(testSeq, false);
                if (pred < 0 || pred >= encoder.size()) {
                    std::cerr << "âš ï¸ æ£€æµ‹åˆ°å¼‚å¸¸é¢„æµ‹ï¼Œé‡ç½®å­¦ä¹ ç‡" << std::endl;
                    initialLr *= 0.5;  // é‡åˆ°å¼‚å¸¸æ—¶é™ä½å­¦ä¹ ç‡
                }
            }
        }
    } catch (const std::exception& e) {
        std::cerr << "âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: " << e.what() << std::endl;
        // å°è¯•ä¿å­˜å½“å‰æ¨¡å‹çŠ¶æ€
        saveModel("emergency_model.bin");
    }
}

std::vector<int> StartModel::strToSeq(const std::string& input) {
    std::vector<int> seq;
    for (size_t i = 0; i < input.size();) {
        unsigned char c = (unsigned char)input[i];
        size_t len = 1;

        // åˆ¤æ–­UTF-8å­—ç¬¦é•¿åº¦
        if ((c & 0xF0) == 0xE0) len = 3;  // æ±‰å­—ä¸º3å­—èŠ‚UTF-8
        else if ((c & 0xE0) == 0xC0) len = 2;
        else if (c >= 0x80) { i++; continue; }  // è·³è¿‡æ— æ•ˆå­—ç¬¦

        if (i + len > input.size()) break;

        std::string hanzi = input.substr(i, len);
        i += len;

        int code = encoder.encode(hanzi);
        if (code != -1) {
            seq.push_back(code);
        }
    }
    return seq;
}

std::string StartModel::seqToStr(const std::vector<int>& seq) {
    std::string s;
    for (int code : seq) {
        s += encoder.decode(code);
    }
    return s;
}

std::vector<int> StartModel::beamSearch(const std::vector<int>& inputSeq, int length,
                                        int beamWidth, double temperature) {
    // é™åˆ¶beamWidthå¤§å°ï¼Œé¿å…å†…å­˜å ç”¨è¿‡é«˜
    beamWidth = std::min(beamWidth, 5);  // å¯¹äºå¤§æ¨¡å‹ï¼Œå‡å°beamWidth

    std::vector<std::pair<std::vector<int>, double>> beams;
    beams.emplace_back(inputSeq, 0.0);

    for (int i = 0; i < length; i++) {
        std::vector<std::pair<std::vector<int>, double>> newBeams;

        for (const auto& beam : beams) {
            const std::vector<int>& seq = beam.first;
            double score = beam.second;

            std::vector<int> context = seq;
            if ((int)context.size() > contextWindow) {
                context = std::vector<int>(context.end() - contextWindow, context.end());
            }

            // å‡å°‘å€™é€‰æ•°é‡ï¼Œé™ä½è®¡ç®—é‡
            std::vector<std::pair<int, double>> candidates;
            int candidateCount = std::min(beamWidth * 2, encoder.size() / 2);
            for (int j = 0; j < candidateCount; j++) {
                int next = model.predict(context, true, temperature);
                candidates.emplace_back(next, -j);
            }

            for (const auto& cand : candidates) {
                std::vector<int> newSeq = seq;
                newSeq.push_back(cand.first);
                newBeams.emplace_back(newSeq, score + cand.second);
            }
        }

        std::sort(newBeams.begin(), newBeams.end(),
                  [](const std::pair<std::vector<int>, double>& a,
                     const std::pair<std::vector<int>, double>& b) {
                      return a.second > b.second;
                  });

        if ((int)newBeams.size() > beamWidth) {
            newBeams.resize(beamWidth);
        }

        beams = newBeams;

        // é˜²æ­¢ç©ºå…‰æŸ
        if (beams.empty()) {
            std::cerr << "âš ï¸ å…‰æŸæœç´¢ä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹åºåˆ—" << std::endl;
            return inputSeq;
        }
    }

    return beams[0].first;
}

std::string StartModel::generateResponse(const std::string& input, int length,
                                         double temperature, bool random) {
    // é™åˆ¶ç”Ÿæˆé•¿åº¦ï¼Œé¿å…å†…å­˜æº¢å‡º
    length = std::min(length, 20);  // å¯¹äºå¤§æ¨¡å‹ï¼Œå‡å°‘ç”Ÿæˆé•¿åº¦

    std::vector<int> inputSeq = strToSeq(input);
    if (inputSeq.empty()) return "æœªè¯†åˆ«åˆ°æœ‰æ•ˆæ±‰å­—";

    try {
        std::vector<int> outputSeq;

        if (length > 10) {
            outputSeq = beamSearch(inputSeq, length, 3, temperature);  // è¿›ä¸€æ­¥å‡å°beamWidth
        } else {
            outputSeq = inputSeq;
            std::vector<int> context = inputSeq;

            for (int i = 0; i < length; i++) {
                if ((int)context.size() > contextWindow) {
                    context = std::vector<int>(context.end() - contextWindow, context.end());
                }

                int next = model.predict(context, random, temperature);
                outputSeq.push_back(next);
                context.push_back(next);
            }
        }

        return seqToStr(outputSeq);
    } catch (const std::exception& e) {
        std::cerr << "âŒ ç”Ÿæˆå“åº”æ—¶å‡ºé”™: " << e.what() << std::endl;
        return "ç”Ÿæˆå“åº”å¤±è´¥ï¼Œè¯·é‡è¯•";
    }
}