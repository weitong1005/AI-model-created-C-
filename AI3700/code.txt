"
AI3700/
â”œâ”€â”€ CMakeLists.txt
â”œâ”€â”€ data
â”‚Â Â  â””â”€â”€ hanzi.txt
â”œâ”€â”€ main.cpp
â”œâ”€â”€ model
â””â”€â”€ src
    â”œâ”€â”€ file_utils.cpp
    â”œâ”€â”€ file_utils.h
    â”œâ”€â”€ hanzi_encoder.cpp
    â”œâ”€â”€ hanzi_encoder.h
    â”œâ”€â”€ matrix.cpp
    â”œâ”€â”€ matrix.h
    â”œâ”€â”€ rnn_model.cpp
    â”œâ”€â”€ rnn_model.h
    â”œâ”€â”€ start_model.cpp
    â””â”€â”€ start_model.h

"

CMakeLists.txt
"
cmake_minimum_required(VERSION 3.10)
project(AI3700)
set(CMAKE_CXX_STANDARD 11)
set(CMAKE_CXX_STANDARD_REQUIRED ON)

# ç¡®ä¿ä¸­æ–‡æ­£å¸¸å¤„ç†
add_compile_options(-finput-charset=UTF-8)
include_directories(src)

add_executable(AI3700
        main.cpp
        src/file_utils.cpp
        src/file_utils.h
        src/hanzi_encoder.cpp
        src/hanzi_encoder.h
        src/matrix.cpp
        src/matrix.h
        src/rnn_model.cpp
        src/rnn_model.h
        src/start_model.cpp
        src/start_model.h
)

# é’ˆå¯¹ä¸åŒå¹³å°çš„ç‰¹å®šè®¾ç½®
if(WIN32)
    # Windows ç‰¹å®šè®¾ç½®
    target_compile_definitions(AI3700 PRIVATE _CRT_SECURE_NO_WARNINGS)
elseif(UNIX)
    # Linux ç‰¹å®šè®¾ç½®
    target_compile_options(AI3700 PRIVATE -Wall -Wextra)
endif()

# è‡ªåŠ¨å¤åˆ¶ hanzi.txt åˆ°æ„å»ºç›®å½•
add_custom_command(
        TARGET AI3700 POST_BUILD
        COMMAND ${CMAKE_COMMAND} -E copy_if_different
        ${CMAKE_SOURCE_DIR}/data/hanzi.txt
        $<TARGET_FILE_DIR:AI3700>
)
"
hanzi.txt
"
a: é˜¿å•Šå“å“€å”‰åŸƒæŒ¨ç™ŒçŸ®è”¼çˆ±ç¢å®‰å²¸æŒ‰æ¡ˆæš—æ˜‚å‡¹ç†¬å‚²å¥¥æ¾³è…Œå–é”•å—„
ba: å…«å·´æ‰’å§ç–¤æ‹”è·‹æŠŠåçˆ¸ç½¢éœ¸æ°ç™½ç™¾æŸæ‘†è´¥æ‹œæ–‘ç­æ¬æ¿ç‰ˆåŠåŠä¼´æ‰®ç“£é‚¦å¸®è†€å‚æ£’åŒ…èƒé›¹å®é¥±ä¿å ¡æŠ¥æŠ±æš´çˆ†æ¯æ‚²ç¢‘åŒ—è´å¤‡èƒŒå€è¢«è¾ˆå¥”æœ¬ç¬¨å´©ç»·è¹¦é€¼é¼»æ¯”å½¼ç¬”é„™å¸å¿…æ¯•é—­åº‡æ¯™ç§˜å¼Šç¢§è”½å£é¿è‡‚è¾¹ç¼–é­æ‰ä¾¿å˜éè¾¨è¾©è¾«æ ‡å½ªè†˜è¡¨æ†‹åˆ«å®¾æ»¨å†°å…µä¸™æŸ„é¥¼å¹¶ç—…æ‹¨æ³¢ç»å‰¥è„–è ä¼¯é©³æ³Šåšæè†Šè–„åœè¡¥æ•ä¸å¸ƒæ­¥æ€–éƒ¨é­ƒç²‘ç¬†é’¯
cai: çŒœæ‰æè´¢è£é‡‡å½©ç¬è¸©èœå‚é¤æ®‹èš•æƒ­æƒ¨ç¿ä»“è‹èˆ±è—æ“ç³™æ§½è‰å†Œä¾§å•æµ‹ç­–å±‚æ›¾å‰æ’æŸ¥å¯ŸèŒ¬èŒ¶æ½å·®æ‹†æŸ´è±ºæ€æºé¦‹ç¼ è‰äº§é“²é˜é¢¤æ˜Œé•¿è‚ å°å¸¸å¿å‚åœºæ•ç•…å€¡å”±æŠ„é’è¶…å·¢æœå˜²æ½®åµç‚’è½¦æ‰¯å½»æ’¤å°˜è‡£æ²‰è¾°é™ˆæ™¨é—¯è¡¬ç§°è¶æ’‘æˆå‘ˆè¯šæ‰¿åŸä¹˜æƒ©ç¨‹æ¾„æ©™é€ç§¤åƒç—´æŒæ± è¿Ÿé©°è€»é½¿æ–¥èµ¤ç¿…å……å†²è™«å´‡å® æŠ½ä»‡ç»¸æ„ç¨ ç­¹é…¬ä¸‘è‡­å‡ºåˆé™¤å¨é”„ç¡€å‚¨æ¥šå¤„è§¦å·ç©¿ä¼ èˆ¹å–˜ä¸²ç–®çª—åºŠåˆ›å¹ç‚Šå‚é”¤æ˜¥çº¯å”‡æ·³é†‡è ¢æˆ³ç»°è¯ç¥ æ…ˆè¾ç£é›Œæ­¤æ¬¡åˆºèµåŒ†è‘±èªä»ä¸›å‡‘ç²—ä¿ƒé†‹ç°‡çªœç¯¡å‚¬æ‘§è„†ç²¹ç¿ æ‘å­˜å¯¸æ“æªé”™å²éª–ç²²
da: æ­è¾¾ç­”æ‰“å¤§å‘†æ­¹ä»£å¸¦å¾…æ€ è´·è¢‹é€®æˆ´ä¸¹å•æ‹…è€½èƒ†æ—¦ä½†è¯å¼¹æ·¡è›‹å½“æŒ¡å…šè¡æ¡£åˆ€å¨å¯¼å²›å€’è¹ˆåˆ°æ‚¼ç›—é“ç¨»å¾—å¾·çš„ç¯ç™»ç­‰çªå‡³ä½å ¤æ»´è¿ªæ•Œç¬›åº•æŠµåœ°å¼Ÿå¸é€’ç¬¬é¢ å…¸ç‚¹ç”µä½ƒåº—å«æ·€æ®¿åˆå¼é›•åŠé’“è°ƒæ‰çˆ¹è·Œå è¶ä¸å®ç›¯é’‰é¡¶è®¢å®šä¸¢ä¸œå†¬è‘£æ‡‚åŠ¨å†»æ ‹æ´éƒ½å…œæŠ–æ–—é™¡è±†é€—éƒ½ç£æ¯’è¯»ç‹¬å µèµŒæœè‚šåº¦æ¸¡ç«¯çŸ­æ®µæ–­ç¼ç……é”»å †é˜Ÿå¯¹å…‘å¨æ•¦è¹²ç›¾é¡¿å¤šå¤ºæœµèº²è€·å“’å—’é‘
e: ä¿„é¹…é¢æ¶é¥¿éæ©å„¿è€Œå°”è€³äºŒè´°å©€è½­è¿©
fa: å‘ä¹ä¼ç½šé˜€ç­æ³•å¸†ç•ªç¿»å‡¡çƒ¦ç¹åè¿”çŠ¯é¥­æ³›èŒƒè´©æ–¹åŠèŠ³é˜²å¦¨æˆ¿ä»¿è®¿çººæ”¾é£éå•¡è‚¥åŒªè¯½å è‚ºåºŸæ²¸è´¹åˆ†èŠ¬å©çº·æ°›åŸç„šç²‰ä»½å¥‹æ„¤ç²ªä¸°é£å°ç–¯å³°é”‹èœ‚é€¢ç¼è®½å‡¤å¥‰ä½›å¦å¤«æ•·è‚¤ä¼æ‰¶æ‹‚æœä¿˜æµ®ç¬¦å¹…ç¦æŠšç”«åºœæ–§ä¿¯è¾…è…çˆ¶ä»˜è´Ÿå¦‡é™„å’å¤èµ´å‰¯å‚…å¯Œè…¹è¦†ç 
ga: å°¬è¯¥æ”¹ç›–æ¦‚é’™å¹²ç”˜æ†è‚ç«¿ç§†èµ¶æ•¢æ„Ÿå¹²å†ˆåˆšçº²ç¼¸é’¢å²—æ¸¯æ é«˜è†ç¯™ç³•æç¨¿å‘Šå“¥æ­Œæå‰²é©è‘›æ ¼éš”ä¸ªå„ç»™æ ¹è·Ÿæ›´è€•å·¥å¼“å…¬åŠŸæ”»ä¾›å®«æ­èº¬å·©æ‹±å…±è´¡å‹¾æ²Ÿé’©ç‹—æ„è´­å¤Ÿä¼°å’•å­¤å§‘å¤è°·è‚¡éª¨é¼“å›ºæ•…é¡¾é›‡ç“œåˆ®æŒ‚ä¹–æ‹æ€ªå…³è§‚å®˜å† æ£ºé¦†ç®¡è´¯æƒ¯çŒç½å…‰å¹¿å½’é¾Ÿè§„é—ºè½¨é¬¼æŸœè´µæ¡‚è·ªæ»šæ£å›½æœè¿‡å°•æ—®
ha: å“ˆå­©æµ·å®³é…£å«å‡½å¯’å–Šç½•æ±‰æ±—æ—±æ‚ç„Šæ†¾æ’¼è¡Œèˆªå··æ¯«è±ªå¥½å·æµ©è€—å‘µå–åˆä½•å’Œæ²³æ ¸è·ç›’è´ºé»‘å˜¿ç—•å¾ˆç‹ æ¨å“¼æ’æ¨ªè¡¡è½°å“„çƒ˜çº¢å®æ´ªè™¹é¸¿ä¾¯å–‰çŒ´å¼ååšå€™ä¹å‘¼å¿½ç‹èƒ¡å£¶æ¹–ç³Šè™äº’æˆ·æŠ¤èŠ±åå“—æ»‘çŒ¾åŒ–åˆ’ç”»è¯æ€€æ§åæ¬¢è¿˜ç¯ç¼“å¹»å”¤æ¢æ‚£ç„•ç–¾è±¢æ…Œçš‡é»„ç…Œæ™ƒè°ç°æŒ¥æ¢è¾‰å›æ¯æ‚”æ±‡ä¼šè®³ç»˜è´¿ç§½æƒ æ…§æ˜å©šæµ‘é­‚æ··è±æ´»ç«ä¼™æˆ–è´§è·ç¥¸æƒ‘é“ªæ°¦åŠ¾
ji: å‡»é¥¥åœ¾æœºè‚Œé¸¡è¿¹ç§¯åŸºç»©æ¿€åŠå‰çº§å³ææ€¥ç–¾é›†ç±å‡ å·±æŒ¤è„Šè®¡è®°çºªå¿ŒæŠ€é™…å‰‚å­£æ—¢æµç»§å¯„å¯‚åŠ å¤¹ä½³å®¶å˜‰ç”²é’¾ä»·é©¾æ¶å‡å«ç¨¼å¥¸å°–åšé—´è‚©è‰°å…¼ç›‘ç…æ‹£ä¿­æŸ¬æ¡æ£€å‡å‰ªç®€è§ä»¶å»ºå‰‘èè´±å¥èˆ°æ¸æº…é‰´é”®ç®­æ±Ÿå°†å§œæµ†åƒµç–†è®²å¥–åŒ é™é…±äº¤éƒŠæµ‡éª„å¨‡èƒ¶æ•™ç„¦åš¼è§’ç‹¡è„šæ…ç¼´å«è½¿è¾ƒè§‰é˜¶çš†æ¥æ­è¡—èŠ‚åŠ«æ°æ´ç»“æ·æˆªç«­å§è§£ä»‹æˆ’å±Šç•Œå€Ÿå·¾æ–¤ä»Šé‡‘æ´¥ç­‹ä»…ç´§é”¦è°¨å°½åŠ²è¿‘è¿›æ™‹æµ¸ç¦äº¬ç»èŒæƒŠæ™¶ç›ç²¾äº•é¢ˆæ™¯è­¦å‡€å¾„ç«ç«Ÿæ•¬å¢ƒé™é•œçº ç©¶ä¹ä¹…é…’æ—§æ•‘å°±èˆ…å±…æ‹˜é å±€èŠæ©˜ä¸¾çŸ©å¥å·¨æ‹’å…·å‰§æƒ§æ®è·é”¯èšæå·å€¦ç»¢å†³ç»è§‰æ˜åš¼å†›å›å‡èŒä¿Šå³»éªä¸Œä¹©å‰æå½éº‚
ka: å’–å¡å¼€æ©å‡¯æ…¨åˆŠå ªç çœ‹åº·æ…·ç³ æ‰›æŠ—ç‚•è€ƒçƒ¤é ç§‘æ£µé¢—å£³å’³å¯æ¸´å…‹åˆ»å®¢è¯¾è‚¯å¦æ³å‘ç©ºå­”ææ§æŠ å£æ‰£æ¯å“­è‹¦åº“è£¤é…·å¤¸è·¨æŒå—å¿«å®½æ¬¾åŒ¡ç­ç‹‚å†µçŸ¿æ¡†æ—·äºçª¥è‘µé­æ„§æºƒæ˜†å›°æ‹¬é˜”å’”ä½§èƒ©
la: åƒæ‹‰å•¦å–‡è…Šèœ¡è¾£æ¥è±èµ–è“æ æ‹¦ç¯®è§ˆæ‡’çƒ‚æ»¥éƒç‹¼å»Šæœ—æµªæåŠ³ç‰¢è€ä½¬å§¥æ¶ä¹å‹’é›·å’æ³ªç±»ç´¯å†·å˜æ¢¨ç¦»ç’ƒé»ç¤¼æé‡Œç†é²¤åŠ›å†å‰ç«‹ä¸½åˆ©åŠ±ä¾‹éš¶ä¿©è¿å¸˜æ€œè²è”å»‰è„¸ç»ƒç‚¼æ‹é“¾è‰¯å‡‰æ¢ç²®ä¸¤äº®è°…è¾†é‡è¾½ç–—èŠåƒšäº†æ–™åˆ—åŠ£çƒˆçŒè£‚é‚»æ—ä¸´æ·‹ç£·çµé“ƒé™µé›¶é¾„é¢†ä»¤å¦æºœåˆ˜ç•™æµç¡«æ¦´æŸ³å…­é¾™è‹éš†å„æ‹¢ç¬¼å¼„æ¥¼æ‚æ¼éœ²å¢èŠ¦ç‚‰é²é™†å½•é¹¿ç¢Œè·¯é©´æ—…å±¡å¾‹è™‘ç»¿æ»¤å‰Œé‚‹æ—¯
ma: å¦ˆéº»é©¬ç›ç èš‚éª‚å—åŸ‹ä¹°éº¦å–è¿ˆè„‰ç’æ»¡æ›¼æ…¢æ¼«å¿™èŠ’ç›²èŒ«çŒ«æ¯›çŸ›èŒ…èŒ‚å†’è´¸å¸½è²Œä¹ˆæ²¡çœ‰æ¢…åª’ç…¤éœ‰æ¯ç¾å¦¹é—¨é—·ä»¬èŒç›ŸçŒ›æ¢¦çœ¯å¼¥è¿·è°œç±³ç§˜è§…å¯†èœœçœ ç»µæ£‰å…å‹‰é¢è‹—æç„ç§’å¦™åº™ç­æ°‘æ•åæ˜é¸£å‘½è°¬æ‘¸æ¨¡è†œæ‘©ç£¨æŠ¹æœ«æ²¡è«å¢¨é»˜è°‹æŸæ¯äº©ç‰¡å§†æ‹‡æœ¨ç›®ç‰§å¢“å¹•æ…•æš®ç©†ç¥ƒçŠ¸æ©
na: æ‹¿å“ªé‚£çº³é’ ä¹ƒå¥¶è€ç”·å—éš¾å›ŠæŒ æ¼è„‘é—¹å‘¢å†…å«©èƒ½å¦®æ³¥ä½ æ‹Ÿé€†å¹´å¿µå¨˜é…¿é¸Ÿå°¿ææ‚¨å®å‡ç‰›æ‰­çº½å†œæµ“å¼„å¥´åŠªæ€’å¥³æš–è™æŒªè¯ºæºè‚­è¡²
ou: æ¬§é¸¥æ®´å¶è—•å‘•æ²¤è€¦æ€„ç“¯
pa: è¶´çˆ¬å¸•æ€•æ‹æ’ç‰Œæ´¾æ”€ç›˜åˆ¤å›ç›¼ä¹“åºæ—èƒ–æŠ›ç‚®è¢è·‘æ³¡å‘¸é™ªåŸ¹èµ”ä½©é…å–·ç›†ç °æŠ¨çƒ¹æœ‹æ£šè“¬ç¡¼é¹æ§ç¢°æ‰¹æŠ«åŠˆçš®ç–²åŒ¹ç—åƒ»å±è­¬ç‰‡åç¯‡éª—é£˜æ¼‚ç¥¨æ’‡æ‹¼è´«é¢‘å“è˜ä¹’å¹³è¯„å‡­è‹¹ç“¶èå¡æ³¼å©†è¿«ç ´é­„å‰–æ‰‘é“ºä»†è‘¡æœ´æ™®è°±ç€‘ç­¢
qi: ä¸ƒå¦»å‡„æˆšæœŸæ¬ºæ¼†é½å…¶å¥‡æ­§éª‘æ£‹æ——ä¹ä¼å²‚å¯èµ·æ°”è¿„å¼ƒæ±½å¥‘ç Œå™¨æ°æ´½åƒè¿ç‰µé“…è°¦ç­¾å‰é’±é’³æ½œæµ…é£æ¬ æ¬¾æªè…”å¼ºå¢™æŠ¢æ‚„æ•²é”¹æ¡¥ç§å·§åˆ‡èŒ„ä¸”çªƒäº²ä¾µèŠ¹ç´ç¦½å‹¤é’æ°¢è½»å€¾æ¸…æƒ…æ™´é¡·è¯·åº†ç©·ä¸˜ç§‹æ±‚çƒåŒºæ›²é©±å±ˆè¶‹æ¸ å–å¨¶å»è¶£åœˆæƒå…¨æ³‰æ‹³çŠ¬åŠåˆ¸ç¼ºå´é›€ç¡®é¹Šä¿Ÿæ±”ç¢›è‘º
ran: ç„¶ç‡ƒæŸ“åš·å£¤è®©é¥¶æ‰°ç»•æƒ¹çƒ­äººä»å¿è®¤ä»»æ‰”ä»æ—¥ç»’è£å®¹ç†”èå†—æŸ”æ‰è‚‰å¦‚å„’ä¹³è¾±å…¥è½¯é”ç‘æ¶¦è‹¥å¼±è‹’èšºé«¯
sa: æ’’æ´’è¨å¡èµ›ä¸‰æ•£æ¡‘å—“ä¸§æ”éªšæ‰«å«‚è‰²æ¶©æ£®åƒ§æ€æ²™çº±å‚»å•¥ç­›æ™’å±±åˆ è¡«é—ªé™•æ‰‡å–„ä¼¤å•†è£³æ™Œèµä¸Šå°šææ¢¢çƒ§ç¨å‹ºå°‘å“¨èˆŒè›‡èˆè®¾ç¤¾å°„æ¶‰æ‘„ç”³ä¼¸èº«æ·±ç¥å®¡å©¶è‚¾ç”šæ¸—æ…å‡ç”Ÿå£°æ€§ç‰²èƒœç»³çœåœ£ç››å‰©å°¸å¤±å¸ˆè¯—æ–½ç‹®æ¹¿åçŸ³æ—¶è¯†å®æ‹¾èš€é£Ÿå²ä½¿å§‹é©¶å£«æ°ä¸–ç¤ºå¸‚å¼ä¼¼äº‹åŠ¿ä¾é¥°è¯•è§†æŸ¿æ˜¯é€‚å®¤é€é‡Šæ”¶æ‰‹å®ˆé¦–å¯¿å—å…½å”®æˆç˜¦ä¹¦å”æ®Šæ¢³ç–èˆ’è¾“è”¬ç†Ÿæš‘å±é¼ æ•°æœ¯æŸè¿°æ ‘ç«–æ•åˆ·è¡°æ‘”ç”©å¸…æ “åŒéœœçˆ½è°æ°´ç¨ç¡é¡ºè¯´å¸ä¸ç§æ€æ–¯æ’•æ­»å››å¯ºä¼¼é¥²è‚†æ¾å®‹é€è¯µæœè‰˜è‹ä¿—è¯‰è‚ƒç´ é€Ÿå®¿å¡‘é…¸è’œç®—è™½éšå²ç¢ç©—å­™æŸç¬‹ç¼©æ‰€ç´¢é”å…æŒ²è„
ta: ä»–å®ƒå¥¹å¡Œå¡”è¸å°æŠ¬å¤ªæ€æ³°è´ªæ‘Šæ»©å›è°ˆç—°æ½­å¦å¹ç‚­æ¢å¹æ±¤å”å ‚å¡˜è†›ç³–å€˜èººè¶Ÿæ¶›ææ»”é€ƒæ¡ƒé™¶æ·˜è®¨å¥—ç‰¹è—¤è…¾ç–¼æ¢¯è¸¢å•¼æé¢˜è¹„ä½“æ›¿å¤©æ·»ç”°ç”œå¡«æŒ‘æ¡è·³è´´é“å…å¬çƒƒå»·äº­åº­åœæŒºè‰‡é€šåŒé“œç«¥ç»Ÿç—›å·å¤´æŠ•é€å‡¸ç§ƒçªå›¾å¾’é€”æ¶‚å± åœŸåå…”å›¢æ¨è…¿é€€åå±¯æ‰˜æ‹–è„±é©¼å¦¥æ‹“å”¾æº»ç­é³
wa: æŒ–å“‡è›™å¨ƒç“¦æ­ªå¤–å¼¯æ¹¾ä¸¸å®Œç©é¡½æŒ½æ™šç¢—ä¸‡æ±ªäº¡ç‹ç½‘å¾€å¿˜æ—ºæœ›å±å¨å¾®ä¸ºå›´è¿å”¯ç»´ä¼ŸéŸ¦ä¼ªå°¾çº¬å§”èå«æœªä½å‘³ç•èƒƒå–‚æ…°æ¸©æ–‡çº¹é—»èšŠç¨³é—®ç¿å—¡çªæˆ‘æ²ƒå§æ¡ä¹Œæ±¡å±‹æ— å´å¾äº”åˆä¼æ­¦ä¾®èˆåŠ¡ç‰©è¯¯æ‚Ÿé›¾è…½å¨²ç•–
xi: å¤•è¥¿å¸å¸Œæ˜”ææ¯ç‰ºæ‚‰æƒœç¨€æºªé”¡ç†„ç†™èœ¥å˜»è†ä¹ å¸­è¢­åª³æ´—å–œæˆç³»ç»†éš™è™¾çå³¡ç‹­éœä¸‹å¤å“ä»™å…ˆçº¤æ€é²œé—²å¼¦å’¸è¡”å«Œæ˜¾é™©å¿ç°é™çº¿å®ªé™·é¦…ç¾¡çŒ®ä¹¡ç›¸é¦™å¢æ¹˜ç®±è¯¦ç¥¥ç¿”äº«å“æƒ³å‘å··é¡¹è±¡åƒæ©¡å‰Šæ¶ˆå®µè§é”€å°æ™“å­æ ¡ç¬‘æ•ˆäº›æ­‡åé‚ªèƒæ–œè°æºé‹å†™æ³„æ³»å¸å±‘æ¢°è°¢å¿ƒè¾›æ¬£æ–°è–ªä¿¡å…´æ˜Ÿè…¥åˆ‘è¡Œå½¢å‹é†’æå§“å¹¸æ€§å…„å‡¶èƒ¸åŒˆé›„ç†Šä¼‘ä¿®ç¾æœ½ç§€ç»£è¢–é¡»è™šéœ€å¾è®¸åºå™ç•œç»ªç»­é…—è“„å®£æ‚¬æ—‹ç„é€‰ç©´å­¦é›ªè¡€å‹‹å¯»å·¡è¯¢å¾ªè®­è®¯è¿…è‘¸èˆ„ç¦Š
ya: å‹æŠ¼é¸¦é¸­ç‰™èŠ½å´–å“‘äºšè®¶å’½çƒŸæ·¹å»¶ä¸¥è¨€å²©æ²¿ç‚ç ”ç›é¢œæªè¡æ©çœ¼æ¼”åŒå®´è‰³éªŒç„°é›ç‡•å¤®æ®ƒç§§æ‰¬ç¾Šé˜³æ¨æ´‹ä»°å…»æ°§ç—’æ ·è…°é‚€æ‘‡é¥å’¬è¯è¦è€€çˆ·ä¹Ÿå†¶é‡ä¸šå¶é¡µå¤œæ¶²ä¸€ä¼Šè¡£åŒ»ä¾ä»ªå¤·å®œå§¨ç§»é—ç–‘ä¹™å·²ä»¥çŸ£èšå€šæ¤…ä¹‰äº¿å¿†è‰ºè®®äº¦å¼‚å½¹æŠ‘è¯‘æ˜“ç–«ç›Šè°Šæ„æº¢æ¯…ç¿¼å› é˜´éŸ³å§»é“¶å¼•é¥®éšå°åº”è‹±å©´æ¨±é¹°è¿ç›ˆè¥è‡èµ¢å½±æ˜ ç¡¬å“Ÿæ‹¥ä½£æ°¸å’æ³³å‹‡ç”¨ä¼˜å¿§å¹½æ‚ å°¤ç”±é‚®çŠ¹æ²¹æ¸¸å‹æœ‰åˆå³å¹¼è¯±äºäºˆä½™é±¼å¨±æ¸”æ„‰æ„šä¸å®‡ç¾½é›¨è¯­ç‰è‚²éƒç‹±æµ´é¢„åŸŸæ¬²é‡å¾¡è£•æ„ˆèª‰å†¤å…ƒå‘˜å›­åŸåœ†æ´ç¼˜æºè¿œæ€¨é™¢æ„¿æ›°çº¦æœˆæ‚¦é˜…è·ƒè¶Šäº‘åŒ€å…è¿å­•èšœçšç—–
za: æ‚ç¾æ ½å®°è½½å†åœ¨å’±æ”’æš‚èµèµƒè„è‘¬é­ç³Ÿæ—©æ£æ¾¡è—»ç¶çš‚é€ å™ªç‡¥èºåˆ™æ‹©æ³½è´£è´¼æ€å¢èµ æ¸£æ‰è½§çœ¨ç‚¸æ‘˜å®…çª„å€ºæ²¾ç²˜å±•å æˆ˜ç«™å¼ ç« æ¶¨æŒä¸ˆä»—å¸èƒ€éšœæ‹›æ‰¾å¬å…†èµµç…§é®æŠ˜å“²è€…è¿™æµ™ççœŸè¯Šé˜µæŒ¯é•‡éœ‡äº‰å¾æŒ£çè’¸æ•´æ­£è¯éƒ‘æ”¿ç—‡ä¹‹æ”¯æ±èŠæçŸ¥è‚¢ç»‡è„‚èœ˜æ‰§ç›´å€¼èŒæ¤æ®–æ­¢åªæ—¨å€çº¸æŒ‡è¶¾è‡³å¿—åˆ¶å¸œæ²»è´¨ç§©è‡´æ™ºç½®ä¸­å¿ ç»ˆé’Ÿè‚¿ç§ä»²ä¼—é‡å·èˆŸå‘¨æ´²ç²¥è½´å®™æ˜¼çš±éª¤æœ±ç æ ªè¯¸çŒªè››ç«¹çƒ›é€ä¸»å±ç…®å˜±ä½åŠ©æ³¨è´®é©»æŸ±ç¥è‘—ç­‘æŠ“çˆªæ‹½ä¸“ç –è½¬èµšåº„è£…å£®çŠ¶æ’è¿½å‡†æ‰æ¡Œç€ä»”å…¹å§¿èµ„æ»‹ç±½å­ç´«å­—è‡ªå®—ç»¼æ£•è¸ªæ€»çºµèµ°å¥ç§Ÿè¶³æ—é˜»ç»„ç¥–é’»å˜´æœ€ç½ªé†‰å°Šéµæ˜¨å·¦ä½œååº§åšåŒæ‹¶å’‚

# è¡¥å……æ±‰å­—ä»¥æ»¡è¶³3700ä¸ª
beng: å´©ç»·æ³µè¹¦è¿¸ç”­å˜£
............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
"

main.cpp

"
#include "hanzi_encoder.h"
#include "file_utils.h"
#include "start_model.h"
#include <iostream>
#include <sys/stat.h>
#include <sys/types.h>
#include <string>
#include <chrono>

#ifdef _WIN32
#include <direct.h>
#else
#include <unistd.h>
#endif

bool createDirectory(const std::string& path) {
#ifdef _WIN32
    return _mkdir(path.c_str()) == 0;
#else
    mode_t mode = 0755;
    return mkdir(path.c_str(), mode) == 0;
#endif
}

bool fileExists(const std::string& path) {
    struct stat buffer;
    return (stat(path.c_str(), &buffer) == 0);
}

int main() {
    auto startTime = std::chrono::high_resolution_clock::now();

    HanziEncoder encoder;
    std::cout << "ğŸ“– åŠ è½½æ±‰å­—åº“...\n";
    if (!encoder.loadFromFile("hanzi.txt")) {
        std::cerr << "âŒ æ±‰å­—åº“åŠ è½½å¤±è´¥ï¼Œè¯·ç¡®ä¿hanzi.txtåœ¨å½“å‰ç›®å½•\n";
        return 1;
    }
    std::cout << "âœ… åŠ è½½ " << encoder.size() << " ä¸ªæ±‰å­—\n";

    std::string modelDir = "model";
    if (!fileExists(modelDir) && !createDirectory(modelDir)) {
        std::cerr << "âŒ æ— æ³•åˆ›å»ºæ¨¡å‹ç›®å½•: " << modelDir << "\n";
        modelDir = ".";
        std::cout << "âš ï¸ æ”¹ç”¨å½“å‰ç›®å½•å­˜å‚¨æ¨¡å‹\n";
    }


    try {
        // é€’å‡éšè—å±‚å¤§å°è‡³8ï¼Œå±‚æ•°ä¿æŒ2
        int hiddenSize = 1;
        int layers = 1000;
        StartModel model(encoder, hiddenSize, layers);
        model.setContextWindow(3);  // è¿›ä¸€æ­¥å‡å°ä¸Šä¸‹æ–‡çª—å£
        model.setActivation(RNNModel::TANH);  // Tanhæ›´ç¨³å®šï¼Œé€‚åˆå°æ¨¡å‹

        std::string modelPath = modelDir + "/model.bin";
        if (!fileExists(modelPath)) {
            std::cout << "\nâ³ é¦–æ¬¡è¿è¡Œï¼Œå¼€å§‹è®­ç»ƒæ¨¡å‹...\n";
            std::cout << "ğŸ’¡ æ¨¡å‹é…ç½®: éšè—å±‚å¤§å°=" << hiddenSize << ", å±‚æ•°=" << layers << "\n";

            // å°æ¨¡å‹å¯ä»¥é€‚å½“å¢åŠ è¿­ä»£æ¬¡æ•°
            int iterations = 20000;
            model.train(iterations, 0.0001);

            std::cout << "ğŸ’¾ ä¿å­˜æ¨¡å‹...\n";
            if (!model.saveModel(modelPath)) {
                std::cerr << "âŒ æ¨¡å‹ä¿å­˜å¤±è´¥ï¼\n";
                return 1;
            } else {
                std::cout << "âœ… æ¨¡å‹ä¿å­˜è‡³ " << modelPath << "\n";
            }
        } else {
            std::cout << "\nğŸ“‚ åŠ è½½å·²æœ‰æ¨¡å‹...\n";
            if (!model.loadModel(modelPath)) {
                std::cerr << "âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°è¯•é‡æ–°è®­ç»ƒ...\n";
                model.train(5000, 0.0001);
                model.saveModel(modelPath);
            }
        }

        auto endTime = std::chrono::high_resolution_clock::now();
        std::chrono::duration<double> elapsed = endTime - startTime;
        std::cout << "\nâ±ï¸  æ¨¡å‹å‡†å¤‡æ—¶é—´: " << elapsed.count() << " ç§’\n";

        std::cout << "\nğŸ’¬ æ¨¡å‹å°±ç»ªï¼Œè¾“å…¥qé€€å‡º\n";
        std::string input;
        while (true) {
            std::cout << "ä½ : ";
            std::getline(std::cin, input);
            if (input == "q") break;

            std::string response = model.generateResponse(input, 8, 0.5, true);
            std::cout << "AI: " << response << "\n\n";
        }
    } catch (const std::bad_alloc& e) {
        std::cerr << "\nâŒ å†…å­˜åˆ†é…å¤±è´¥ï¼å°è¯•æ›´å°çš„éšè—å±‚ï¼ˆ4ï¼‰\n";
        return 1;
    } catch (const std::exception& e) {
        std::cerr << "\nâŒ ç¨‹åºé”™è¯¯: " << e.what() << "\n";
        return 1;
    }

    return 0;
}
"

file_utils.cpp
"
#include "file_utils.h"
#include <fstream>

bool FileUtils::generateDataFiles(const HanziEncoder& encoder,
                                  const std::string& dataFile,
                                  const std::string& codeFile) {
    // ç”Ÿæˆæ•°æ®æ–‡ä»¶
    std::ofstream dataOut(dataFile, std::ios::binary);
    if (!dataOut) return false;

    int count = encoder.size();
    dataOut.write(reinterpret_cast<const char*>(&count), sizeof(count));

    for (int i = 0; i < count; ++i) {
        std::string hanzi = encoder.decode(i);
        int len = hanzi.size();
        dataOut.write(reinterpret_cast<const char*>(&len), sizeof(len));
        dataOut.write(hanzi.data(), len);
    }
    dataOut.close();

    // ç”Ÿæˆç¼–ç æ–‡ä»¶
    std::ofstream codeOut(codeFile, std::ios::binary);
    if (!codeOut) return false;

    codeOut.write(reinterpret_cast<const char*>(&count), sizeof(count));
    for (int i = 0; i < count; ++i) {
        std::string hanzi = encoder.decode(i);
        int len = hanzi.size();
        codeOut.write(reinterpret_cast<const char*>(&len), sizeof(len));
        codeOut.write(hanzi.data(), len);
        codeOut.write(reinterpret_cast<const char*>(&i), sizeof(i));
    }
    codeOut.close();

    return true;
}

// loadFromDataFiles å®ç°ä¿æŒä¸å˜
"

file_utils.h
"
#ifndef AI3700_FILE_UTILS_H
#define AI3700_FILE_UTILS_H

#include "hanzi_encoder.h"
#include <string>

class FileUtils {
public:
    static bool generateDataFiles(const HanziEncoder& encoder,
                                  const std::string& dataFile = "hanzi_data.bin",
                                  const std::string& codeFile = "hanzi_codes.bin");

    static bool loadFromDataFiles(HanziEncoder& encoder,
                                  const std::string& dataFile = "hanzi_data.bin",
                                  const std::string& codeFile = "hanzi_codes.bin");
};

#endif
"

hanzi_encoder.cpp
"
#include "hanzi_encoder.h"
#include <fstream>
#include <iostream>
#include <cctype>
#include <algorithm>

void HanziEncoder::clear() {
    hanziToId.clear();
    idToHanzi.clear();
}

bool HanziEncoder::loadFromFile(const std::string& filename) {
    clear();
    std::ifstream infile(filename);
    if (!infile) {
        std::cerr << "æ— æ³•æ‰“å¼€æ–‡ä»¶: " << filename << std::endl;
        return false;
    }

    std::string line;
    int totalAdded = 0;
    int lineNumber = 0;

    while (std::getline(infile, line)) {
        lineNumber++;
        if (line.empty()) continue;

        // æå–æ±‰å­—éƒ¨åˆ†ï¼ˆè·³è¿‡æ‹¼éŸ³ï¼‰
        size_t pos = line.find(':');
        if (pos == std::string::npos) continue;

        std::string hanziBlock = line.substr(pos + 1);

        // ç§»é™¤æ‰€æœ‰ç©ºæ ¼å’Œæ˜Ÿå·
        hanziBlock.erase(std::remove_if(hanziBlock.begin(), hanziBlock.end(),
                                        [](char c) { return std::isspace(static_cast<unsigned char>(c)) || c == '*'; }),
                         hanziBlock.end());

        // å¤„ç†è¿ç»­UTF-8å­—ç¬¦
        for (size_t i = 0; i < hanziBlock.size();) {
            int len = 0;
            unsigned char c = static_cast<unsigned char>(hanziBlock[i]);

            if (c < 0x80) {
                len = 1;  // ASCIIå­—ç¬¦
            } else if ((c & 0xE0) == 0xC0) {
                len = 2;  // 2å­—èŠ‚UTF-8
            } else if ((c & 0xF0) == 0xE0) {
                len = 3;  // 3å­—èŠ‚UTF-8ï¼ˆå¤§å¤šæ•°æ±‰å­—ï¼‰
            } else if ((c & 0xF8) == 0xF0) {
                len = 4;  // 4å­—èŠ‚UTF-8
            } else {
                i++;  // è·³è¿‡æ— æ•ˆå­—èŠ‚
                continue;
            }

            if (i + len > hanziBlock.size()) break;

            std::string hanzi = hanziBlock.substr(i, len);
            i += len;

            // æ·»åŠ åˆ°ç¼–ç å™¨
            if (hanziToId.find(hanzi) == hanziToId.end()) {
                hanziToId[hanzi] = idToHanzi.size();
                idToHanzi.push_back(hanzi);
                totalAdded++;
            }
        }
    }

    std::cout << "æˆåŠŸåŠ è½½ " << totalAdded << " ä¸ªæ±‰å­—\n";
    return true;
}

int HanziEncoder::encode(const std::string& hanzi) const {
    auto it = hanziToId.find(hanzi);
    return (it != hanziToId.end()) ? it->second : -1;
}

std::string HanziEncoder::decode(int code) const {
    return (code >= 0 && code < static_cast<int>(idToHanzi.size())) ? idToHanzi[code] : "";
}

int HanziEncoder::size() const {
    return static_cast<int>(idToHanzi.size());
}
"

hanzi_encoder.h
"
#ifndef AI3700_HANZI_ENCODER_H
#define AI3700_HANZI_ENCODER_H

#include <string>
#include <unordered_map>
#include <vector>

class HanziEncoder {
public:
    bool loadFromFile(const std::string& filename);
    int encode(const std::string& hanzi) const;
    std::string decode(int code) const;
    int size() const;
    void clear();

private:
    std::unordered_map<std::string, int> hanziToId;
    std::vector<std::string> idToHanzi;
};

#endif
"

matrix.cpp
"
#include "matrix.h"
#include <cstdlib>
#include <ctime>

Matrix::Matrix(int rows, int cols, bool random) : rows(rows), cols(cols) {
    data.resize(rows, std::vector<double>(cols, 0.0));
    if (random) {
        std::srand(std::time(nullptr));
        randomize();
    }
}

Matrix::Matrix(const std::vector<std::vector<double>>& initData)
        : data(initData), rows(initData.size()), cols(initData[0].size()) {}

Matrix Matrix::operator+(const Matrix& other) const {
    if (rows != other.rows || cols != other.cols) {
        std::cerr << "çŸ©é˜µåŠ æ³•ç»´åº¦ä¸åŒ¹é…: (" << rows << "x" << cols
                  << ") + (" << other.rows << "x" << other.cols << ")\n";
        return Matrix();
    }

    Matrix result(rows, cols);
    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            result.data[i][j] = data[i][j] + other.data[i][j];
    return result;
}

Matrix Matrix::operator-(const Matrix& other) const {
    if (rows != other.rows || cols != other.cols) {
        std::cerr << "çŸ©é˜µå‡æ³•ç»´åº¦ä¸åŒ¹é…: (" << rows << "x" << cols
                  << ") - (" << other.rows << "x" << other.cols << ")\n";
        return Matrix();
    }

    Matrix result(rows, cols);
    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            result.data[i][j] = data[i][j] - other.data[i][j];
    return result;
}

Matrix Matrix::operator*(const Matrix& other) const {
    if (cols != other.rows) {
        std::cerr << "è‡´å‘½é”™è¯¯ï¼šçŸ©é˜µä¹˜æ³•ç»´åº¦ä¸åŒ¹é… (" << rows << "x" << cols
                  << ") * (" << other.rows << "x" << other.cols << ")\n";
        std::exit(1);
    }

    Matrix result(rows, other.cols);
    for (int i = 0; i < rows; i++) {
        for (int k = 0; k < cols; k++) {
            if (data[i][k] == 0) continue;
            for (int j = 0; j < other.cols; j++) {
                result.data[i][j] += data[i][k] * other.data[k][j];
            }
        }
    }
    return result;
}

Matrix Matrix::operator*(double scalar) const {
    Matrix result(rows, cols);
    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            result.data[i][j] = data[i][j] * scalar;
    return result;
}

Matrix Matrix::operator/(double scalar) const {
    Matrix result(rows, cols);
    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            result.data[i][j] = data[i][j] / scalar;
    return result;
}

Matrix& Matrix::operator+=(const Matrix& other) {
    if (rows != other.rows || cols != other.cols) {
        std::cerr << "çŸ©é˜µåŠ æ³•ç»´åº¦ä¸åŒ¹é…\n";
        return *this;
    }

    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            data[i][j] += other.data[i][j];
    return *this;
}

Matrix& Matrix::operator-=(const Matrix& other) {
    if (rows != other.rows || cols != other.cols) {
        std::cerr << "çŸ©é˜µå‡æ³•ç»´åº¦ä¸åŒ¹é…\n";
        return *this;
    }

    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            data[i][j] -= other.data[i][j];
    return *this;
}

Matrix& Matrix::operator*=(double scalar) {
    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            data[i][j] *= scalar;
    return *this;
}

Matrix Matrix::transpose() const {
    Matrix result(cols, rows);
    for (int i = 0; i < rows; i++) {
        for (int j = 0; j < cols; j++) {
            result.data[j][i] = data[i][j];
        }
    }
    return result;
}

Matrix Matrix::sigmoid(const Matrix& m) {
    Matrix result(m.rows, m.cols);
    for (int i = 0; i < m.rows; i++)
        for (int j = 0; j < m.cols; j++)
            result.data[i][j] = 1.0 / (1.0 + exp(-m.data[i][j]));
    return result;
}

Matrix Matrix::sigmoidDerivative(const Matrix& m) {
    Matrix s = sigmoid(m);
    Matrix result(m.rows, m.cols);
    for (int i = 0; i < m.rows; i++)
        for (int j = 0; j < m.cols; j++)
            result.data[i][j] = s.data[i][j] * (1 - s.data[i][j]);
    return result;
}

Matrix Matrix::tanh(const Matrix& m) {
    Matrix result(m.rows, m.cols);
    for (int i = 0; i < m.rows; i++)
        for (int j = 0; j < m.cols; j++)
            result.data[i][j] = std::tanh(m.data[i][j]);
    return result;
}

Matrix Matrix::tanhDerivative(const Matrix& m) {
    Matrix result(m.rows, m.cols);
    for (int i = 0; i < m.rows; i++)
        for (int j = 0; j < m.cols; j++) {
            double t = std::tanh(m.data[i][j]);
            result.data[i][j] = 1 - t * t;
        }
    return result;
}

Matrix Matrix::relu(const Matrix& m) {
    Matrix result(m.rows, m.cols);
    for (int i = 0; i < m.rows; i++)
        for (int j = 0; j < m.cols; j++)
            result.data[i][j] = std::max(0.0, m.data[i][j]);
    return result;
}

Matrix Matrix::reluDerivative(const Matrix& m) {
    Matrix result(m.rows, m.cols);
    for (int i = 0; i < m.rows; i++)
        for (int j = 0; j < m.cols; j++)
            result.data[i][j] = (m.data[i][j] > 0) ? 1.0 : 0.0;
    return result;
}

Matrix Matrix::leakyRelu(const Matrix& m, double alpha) {
    Matrix result(m.rows, m.cols);
    for (int i = 0; i < m.rows; i++)
        for (int j = 0; j < m.cols; j++)
            result.data[i][j] = std::max(alpha * m.data[i][j], m.data[i][j]);
    return result;
}

Matrix Matrix::leakyReluDerivative(const Matrix& m, double alpha) {
    Matrix result(m.rows, m.cols);
    for (int i = 0; i < m.rows; i++)
        for (int j = 0; j < m.cols; j++)
            result.data[i][j] = (m.data[i][j] > 0) ? 1.0 : alpha;
    return result;
}

void Matrix::randomize(double min, double max) {
    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            data[i][j] = min + (max - min) * ((double)rand() / RAND_MAX);
}

void Matrix::zeros() {
    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            data[i][j] = 0.0;
}

void Matrix::ones() {
    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            data[i][j] = 1.0;
}
"

matrix.h
"
#ifndef AI3700_MATRIX_H
#define AI3700_MATRIX_H
#include <vector>
#include <iostream>
#include <cmath>

class Matrix {
public:
    std::vector<std::vector<double>> data;
    int rows;
    int cols;

    Matrix() : rows(0), cols(0) {}
    Matrix(int rows, int cols, bool random = false);
    Matrix(const std::vector<std::vector<double>>& initData);

    // çŸ©é˜µè¿ç®—
    Matrix operator+(const Matrix& other) const;
    Matrix operator-(const Matrix& other) const;
    Matrix operator*(const Matrix& other) const;
    Matrix operator*(double scalar) const;
    Matrix operator/(double scalar) const;
    Matrix& operator+=(const Matrix& other);
    Matrix& operator-=(const Matrix& other);
    Matrix& operator*=(double scalar);

    Matrix transpose() const;

    // æ¿€æ´»å‡½æ•°
    static Matrix sigmoid(const Matrix& m);
    static Matrix sigmoidDerivative(const Matrix& m);
    static Matrix tanh(const Matrix& m);
    static Matrix tanhDerivative(const Matrix& m);
    static Matrix relu(const Matrix& m);
    static Matrix reluDerivative(const Matrix& m);
    static Matrix leakyRelu(const Matrix& m, double alpha = 0.01);
    static Matrix leakyReluDerivative(const Matrix& m, double alpha = 0.01);

    // è¾…åŠ©å‡½æ•°
    void randomize(double min = -0.5, double max = 0.5);
    void zeros();
    void ones();
    void printDimensions(const std::string& name) const {
        std::cout << name << " dimensions: " << rows << "x" << cols << std::endl;
    }
};

#endif //AI3700_MATRIX_H
"

rnn_model.cpp
"
#include "rnn_model.h"
#include <fstream>
#include <cmath>
#include <iostream>
#include <random>
#include <stdexcept>

// æ·»åŠ NaNæ£€æŸ¥å‡½æ•°
bool isNaN(double x) {
    return x != x;
}

// æ·»åŠ æ¢¯åº¦è£å‰ªå‡½æ•°
void clipGradients(Matrix& grad, double maxNorm) {
    double norm = 0.0;
    for (int i = 0; i < grad.rows; i++) {
        for (int j = 0; j < grad.cols; j++) {
            norm += grad.data[i][j] * grad.data[i][j];
        }
    }
    norm = sqrt(norm);

    if (norm > maxNorm && norm > 0) {
        double scale = maxNorm / norm;
        grad *= scale;
    }
}

RNNModel::RNNModel(int vocabSize, int hiddenSize, int layers)
        : vocabSize(vocabSize), hiddenSize(hiddenSize), layers(layers), activationType(TANH) {
    // æ”¹è¿›æƒé‡åˆå§‹åŒ–ï¼šä½¿ç”¨Xavieråˆå§‹åŒ–ï¼Œè§£å†³åˆå§‹å€¼è¿‡å¤§é—®é¢˜
    double wxhScale = sqrt(1.0 / vocabSize);
    Wxh = Matrix(hiddenSize, vocabSize, true);
    Wxh *= wxhScale;  // æ ¹æ®è¾“å…¥ç»´åº¦ç¼©æ”¾

    Whh.resize(layers);
    double whhScale = sqrt(1.0 / hiddenSize);
    for (int i = 0; i < layers; i++) {
        Whh[i] = Matrix(hiddenSize, hiddenSize, true);
        Whh[i] *= whhScale;  // æ ¹æ®éšè—å±‚ç»´åº¦ç¼©æ”¾
    }

    double whyScale = sqrt(1.0 / hiddenSize);
    Why = Matrix(vocabSize, hiddenSize, true);
    Why *= whyScale;

    // åç½®åˆå§‹åŒ–ä¸ºè¾ƒå°çš„å¸¸æ•°ï¼Œé¿å…åˆå§‹ä¸º0
    bh.resize(layers, Matrix(hiddenSize, 1));
    for (int i = 0; i < layers; i++) {
        for (int j = 0; j < hiddenSize; j++) {
            bh[i].data[j][0] = 0.01;  // å°çš„æ­£å€¼åˆå§‹åŒ–
        }
    }

    by = Matrix(vocabSize, 1);
    for (int i = 0; i < vocabSize; i++) {
        by.data[i][0] = 0.01;
    }

    // åˆå§‹åŒ–Adamä¼˜åŒ–å™¨å‚æ•°
    optWxh.m = Matrix(hiddenSize, vocabSize);
    optWxh.v = Matrix(hiddenSize, vocabSize);
    optWhy.m = Matrix(vocabSize, hiddenSize);
    optWhy.v = Matrix(vocabSize, hiddenSize);

    optWhh.resize(layers);
    optBh.resize(layers);
    for (int i = 0; i < layers; i++) {
        optWhh[i].m = Matrix(hiddenSize, hiddenSize);
        optWhh[i].v = Matrix(hiddenSize, hiddenSize);
        optBh[i].m = Matrix(hiddenSize, 1);
        optBh[i].v = Matrix(hiddenSize, 1);
    }

    optBy.m = Matrix(vocabSize, 1);
    optBy.v = Matrix(vocabSize, 1);
}

Matrix RNNModel::activate(const Matrix& m) {
    // æ¿€æ´»å‡½æ•°è¾“å‡ºåæ£€æŸ¥å¹¶å¤„ç†NaN
    Matrix result = Matrix::leakyRelu(m);  // Leaky ReLUæ›´ä¸å®¹æ˜“å‡ºç°æ­»äº¡ç¥ç»å…ƒ

    // æ£€æŸ¥å¹¶æ›¿æ¢NaNå€¼
    for (int i = 0; i < result.rows; i++) {
        for (int j = 0; j < result.cols; j++) {
            if (isNaN(result.data[i][j])) {
                result.data[i][j] = 0.01;  // ç”¨å°å€¼æ›¿æ¢NaN
            }
        }
    }

    return result;
}

Matrix RNNModel::activateDerivative(const Matrix& m) {
    return Matrix::leakyReluDerivative(m);
}

// æ”¹è¿›çš„softmaxå‡½æ•°ï¼Œæ·»åŠ æ•°å€¼ç¨³å®šå¤„ç†
Matrix softmax(const Matrix& m) {
    Matrix result(m.rows, m.cols);
    double maxVal = m.data[0][0];

    // æ‰¾åˆ°æœ€å¤§å€¼ï¼Œç”¨äºæ•°å€¼ç¨³å®š
    for (int i = 0; i < m.rows; i++) {
        if (m.data[i][0] > maxVal) {
            maxVal = m.data[i][0];
        }
    }

    // è®¡ç®—æŒ‡æ•°å¹¶å‡å»æœ€å¤§å€¼é˜²æ­¢æº¢å‡º
    double sum = 0.0;
    for (int i = 0; i < m.rows; i++) {
        result.data[i][0] = exp(m.data[i][0] - maxVal);
        sum += result.data[i][0];
    }

    // å½’ä¸€åŒ–
    for (int i = 0; i < m.rows; i++) {
        result.data[i][0] /= sum;
        // å¤„ç†å¯èƒ½çš„NaNï¼ˆå½“sumä¸º0æ—¶ï¼‰
        if (isNaN(result.data[i][0])) {
            result.data[i][0] = 1.0 / m.rows;
        }
    }

    return result;
}

// ä¿®æ”¹forwardæ–¹æ³•ä¸­çš„çŸ©é˜µè¿ç®—éƒ¨åˆ†
RNNModel::ForwardCache RNNModel::forward(const std::vector<int>& inputs) {
    ForwardCache cache(layers, hiddenSize, vocabSize);

    for (size_t t = 0; t < inputs.size(); t++) {
        int idx = inputs[t];
        if (idx < 0 || idx >= vocabSize) {
            std::cerr << "æ— æ•ˆæ±‰å­—ç´¢å¼•: " << idx << "\n";
            std::exit(1);
        }

        // è¾“å…¥å±‚ç‹¬çƒ­ç¼–ç  [vocabSize x 1]
        Matrix x(vocabSize, 1);
        x.data[idx][0] = 1.0;

        // ç¬¬ä¸€å±‚è®¡ç®—ï¼šä¿®å¤çŸ©é˜µç»´åº¦ä¸åŒ¹é…
        // [hiddenSize x 1] = ([hiddenSize x vocabSize] * [vocabSize x 1]) +
        //                   ([hiddenSize x hiddenSize] * [hiddenSize x 1]) + [hiddenSize x 1]
        Matrix wxhResult = Wxh * x;          // [hiddenSize x 1]
        Matrix whhResult = Whh[0] * cache.h[0];  // [hiddenSize x 1]
        cache.a[0] = wxhResult + whhResult + bh[0];  // æ­£ç¡®çš„ç»´åº¦ç›¸åŠ 
        cache.h[0] = activate(cache.a[0]);

        // æ·±å±‚è®¡ç®—
        for (int l = 1; l < layers; l++) {
            // [hiddenSize x 1] = [hiddenSize x hiddenSize] * [hiddenSize x 1] + [hiddenSize x 1]
            cache.a[l] = Whh[l] * cache.h[l-1] + bh[l];
            cache.h[l] = activate(cache.a[l]);
        }

        // è¾“å‡ºå±‚è®¡ç®— [vocabSize x 1] = [vocabSize x hiddenSize] * [hiddenSize x 1] + [vocabSize x 1]
        cache.y = Why * cache.h[layers-1] + by;
    }

    return cache;
}

void RNNModel::adamUpdate(Matrix& param, AdamParams& opt, const Matrix& grad, double lr, int t) {
    // å¤åˆ¶æ¢¯åº¦ç”¨äºä¿®æ”¹
    Matrix safeGrad = grad;

    // æ£€æŸ¥å¹¶æ›¿æ¢æ¢¯åº¦ä¸­çš„NaN
    for (int i = 0; i < safeGrad.rows; i++) {
        for (int j = 0; j < safeGrad.cols; j++) {
            if (isNaN(safeGrad.data[i][j])) {
                safeGrad.data[i][j] = 0.0;  // NaNæ¢¯åº¦æ›¿æ¢ä¸º0
            }
        }
    }

    // æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
    clipGradients(safeGrad, 5.0);  // æœ€å¤§èŒƒæ•°è®¾ä¸º5.0

    for (int i = 0; i < param.rows; i++) {
        for (int j = 0; j < param.cols; j++) {
            // æ›´æ–°ä¸€é˜¶çŸ©ä¼°è®¡
            opt.m.data[i][j] = opt.beta1 * opt.m.data[i][j] + (1 - opt.beta1) * safeGrad.data[i][j];
            // æ›´æ–°äºŒé˜¶çŸ©ä¼°è®¡
            opt.v.data[i][j] = opt.beta2 * opt.v.data[i][j] + (1 - opt.beta2) * safeGrad.data[i][j] * safeGrad.data[i][j];

            // åå·®ä¿®æ­£
            double m_hat = opt.m.data[i][j] / (1 - pow(opt.beta1, t));
            double v_hat = opt.v.data[i][j] / (1 - pow(opt.beta2, t));

            // å‚æ•°æ›´æ–°ï¼Œæ·»åŠ é¢å¤–ä¿æŠ¤é˜²æ­¢NaN
            if (!isNaN(m_hat) && !isNaN(v_hat) && v_hat > 0) {
                param.data[i][j] -= lr * m_hat / (sqrt(v_hat) + opt.epsilon);
            }

            // æœ€åæ£€æŸ¥å‚æ•°æ˜¯å¦ä¸ºNaN
            if (isNaN(param.data[i][j])) {
                param.data[i][j] = 0.01;  // é‡ç½®ä¸ºå°å€¼
            }
        }
    }
}

void RNNModel::train(const std::vector<int>& sequence, double learningRate, int epoch) {
    if (sequence.size() < 2) return;

    std::vector<int> inputs(sequence.begin(), sequence.end() - 1);
    std::vector<int> targets(sequence.begin() + 1, sequence.end());

    auto cache = forward(inputs);
    int lastTarget = targets.back();
    if (lastTarget < 0 || lastTarget >= vocabSize) return;

    // è¾“å‡ºè¯¯å·® [vocabSize x 1]
    Matrix dy(vocabSize, 1);
    for (int i = 0; i < vocabSize; i++) {
        dy.data[i][0] = cache.y.data[i][0] - (i == lastTarget ? 1.0 : 0.0);
    }

    // è®¡ç®—è¯¯å·®é¡¹
    std::vector<Matrix> dh(layers, Matrix(hiddenSize, 1));

    // æœ€åä¸€å±‚éšè—å±‚è¯¯å·®
    Matrix whyT = Why.transpose();  // [hiddenSize x vocabSize]
    dh[layers-1] = whyT * dy;       // [hiddenSize x 1] = [hiddenSize x vocabSize] * [vocabSize x 1]
    dh[layers-1] = dh[layers-1] * activateDerivative(cache.a[layers-1]);

    // æ·±å±‚è¯¯å·®åå‘ä¼ æ’­
    for (int l = layers-2; l >= 0; l--) {
        Matrix whhT = Whh[l+1].transpose();  // [hiddenSize x hiddenSize]
        dh[l] = whhT * dh[l+1];              // [hiddenSize x 1] = [hiddenSize x hiddenSize] * [hiddenSize x 1]
        dh[l] = dh[l] * activateDerivative(cache.a[l]);
    }

    // æ›´æ–°æƒé‡ï¼ˆç¡®ä¿æ‰€æœ‰çŸ©é˜µä¹˜æ³•ç»´åº¦æ­£ç¡®ï¼‰
    Matrix whyGrad = dy * cache.h[layers-1].transpose();  // [vocabSize x hiddenSize]
    adamUpdate(Why, optWhy, whyGrad, learningRate, epoch);

    // æ›´æ–°ç¬¬ä¸€å±‚æƒé‡
    Matrix x(vocabSize, 1);
    x.data[inputs.back()][0] = 1.0;
    Matrix wxhGrad = dh[0] * x.transpose();  // [hiddenSize x vocabSize]
    adamUpdate(Wxh, optWxh, wxhGrad, learningRate, epoch);

    // æ›´æ–°éšè—å±‚æƒé‡
    for (int l = 0; l < layers; l++) {
        Matrix hPrev = (l == 0) ? cache.h[0] : cache.h[l-1];
        Matrix whhGrad = dh[l] * hPrev.transpose();  // [hiddenSize x hiddenSize]
        adamUpdate(Whh[l], optWhh[l], whhGrad, learningRate, epoch);
        adamUpdate(bh[l], optBh[l], dh[l], learningRate, epoch);
    }

    adamUpdate(by, optBy, dy, learningRate, epoch);
}

int RNNModel::predict(const std::vector<int>& inputSeq, bool random, double temperature) {
    auto cache = forward(inputSeq);

    // åº”ç”¨æ¸©åº¦è°ƒæ•´æ¦‚ç‡åˆ†å¸ƒï¼Œä½¿ç”¨ç¨³å®šçš„softmax
    Matrix probs = softmax(cache.y);

    // æ¸©åº¦è°ƒæ•´
    for (int i = 0; i < vocabSize; i++) {
        if (probs.data[i][0] <= 0) {
            probs.data[i][0] = 1e-10;  // é˜²æ­¢log(0)
        }
        probs.data[i][0] = pow(probs.data[i][0], 1.0 / temperature);
    }

    // å½’ä¸€åŒ–æ¦‚ç‡
    double sum = 0.0;
    for (int i = 0; i < vocabSize; i++) {
        sum += probs.data[i][0];
    }

    // å¤„ç†sumä¸º0çš„æƒ…å†µ
    if (sum <= 0) {
        for (int i = 0; i < vocabSize; i++) {
            probs.data[i][0] = 1.0 / vocabSize;
        }
        sum = 1.0;
    }

    for (int i = 0; i < vocabSize; i++) {
        probs.data[i][0] /= sum;
        // æœ€ç»ˆæ£€æŸ¥NaN
        if (isNaN(probs.data[i][0])) {
            probs.data[i][0] = 1.0 / vocabSize;
        }
    }

    if (!random) {
        // é€‰æ‹©æ¦‚ç‡æœ€å¤§çš„å­—ç¬¦
        int maxIdx = 0;
        double maxVal = probs.data[0][0];
        for (int i = 1; i < vocabSize; i++) {
            if (probs.data[i][0] > maxVal) {
                maxVal = probs.data[i][0];
                maxIdx = i;
            }
        }
        return maxIdx;
    } else {
        // åŸºäºæ¦‚ç‡åˆ†å¸ƒéšæœºé€‰æ‹©
        std::random_device rd;
        std::mt19937 gen(rd());
        std::uniform_real_distribution<> dis(0.0, 1.0);
        double r = dis(gen);

        double accum = 0.0;
        for (int i = 0; i < vocabSize; i++) {
            accum += probs.data[i][0];
            if (accum >= r) {
                return i;
            }
        }
        return vocabSize - 1; // fallback
    }
}

// ä¿æŒå…¶ä»–å‡½æ•°ä¸å˜...
bool RNNModel::save(const std::string& filename) {
    std::ofstream fout(filename, std::ios::binary);
    if (!fout) return false;

    fout.write((char*)&vocabSize, sizeof(vocabSize));
    fout.write((char*)&hiddenSize, sizeof(hiddenSize));
    fout.write((char*)&layers, sizeof(layers));
    fout.write((char*)&activationType, sizeof(activationType));

    auto saveMatrix = [&](const Matrix& m) {
        fout.write((char*)&m.rows, sizeof(m.rows));
        fout.write((char*)&m.cols, sizeof(m.cols));
        for (const auto& row : m.data)
            fout.write((char*)row.data(), row.size() * sizeof(double));
    };

    saveMatrix(Wxh);
    for (const auto& m : Whh) saveMatrix(m);
    saveMatrix(Why);
    for (const auto& m : bh) saveMatrix(m);
    saveMatrix(by);

    return true;
}

bool RNNModel::load(const std::string& filename) {
    std::ifstream fin(filename, std::ios::binary);
    if (!fin) return false;

    fin.read((char*)&vocabSize, sizeof(vocabSize));
    fin.read((char*)&hiddenSize, sizeof(hiddenSize));
    fin.read((char*)&layers, sizeof(layers));

    int actType;
    fin.read((char*)&actType, sizeof(actType));
    activationType = static_cast<ActivationType>(actType);

    auto loadMatrix = [&](Matrix& m) {
        int rows, cols;
        fin.read((char*)&rows, sizeof(rows));
        fin.read((char*)&cols, sizeof(cols));
        m = Matrix(rows, cols);
        for (int i = 0; i < rows; i++) {
            m.data[i].resize(cols);
            fin.read((char*)m.data[i].data(), cols * sizeof(double));
        }
    };

    loadMatrix(Wxh);
    Whh.resize(layers);
    for (int i = 0; i < layers; i++) loadMatrix(Whh[i]);
    loadMatrix(Why);
    bh.resize(layers);
    for (int i = 0; i < layers; i++) loadMatrix(bh[i]);
    loadMatrix(by);

    // é‡æ–°åˆå§‹åŒ–ä¼˜åŒ–å™¨å‚æ•°
    optWxh = AdamParams();
    optWhy = AdamParams();
    optWhh.resize(layers);
    optBh.resize(layers);
    optBy = AdamParams();

    return true;
}

void RNNModel::selfLearn(int iterations, int seqLen, double lr) {
    double currentLr = lr;
    int consecutiveErrors = 0;

    for (int i = 0; i < iterations; i++) {
        try {
            std::vector<int> seq;
            for (int j = 0; j < seqLen; j++) {
                seq.push_back(rand() % vocabSize);
            }

            // æ¯1000æ¬¡è¿­ä»£é™ä½ä¸€æ¬¡å­¦ä¹ ç‡
            if (i % 1000 == 0 && i > 0) {
                currentLr *= 0.95;  // 5%è¡°å‡ç‡
            }

            train(seq, currentLr, i);
            consecutiveErrors = 0;  // é‡ç½®é”™è¯¯è®¡æ•°

            // æ¯5000æ¬¡è¿­ä»£è¾“å‡ºè¿›åº¦
            if (i % 5000 == 0) {
                printf("ğŸ“Š è®­ç»ƒè¿›åº¦: %.1f%% (è¿­ä»£ %d/%d)\n",
                       (double)i/iterations*100, i, iterations);
            }
        } catch (const std::exception& e) {
            std::cerr << "âŒ è®­ç»ƒæ­¥éª¤å¤±è´¥: " << e.what() << "\n";
            consecutiveErrors++;

            // å¦‚æœè¿ç»­å‡ºé”™ï¼Œé™ä½å­¦ä¹ ç‡
            if (consecutiveErrors >= 5) {
                currentLr *= 0.5;
                std::cerr << "âš ï¸ è¿ç»­é”™è¯¯ï¼Œé™ä½å­¦ä¹ ç‡è‡³: " << currentLr << "\n";
                consecutiveErrors = 0;

                // å¦‚æœå­¦ä¹ ç‡è¿‡å°ï¼Œä»ç„¶å‡ºé”™ï¼Œåˆ™ç»ˆæ­¢è®­ç»ƒ
                if (currentLr < 1e-8) {
                    throw std::runtime_error("å­¦ä¹ ç‡å·²è¿‡å°ä½†ä»å‡ºé”™ï¼Œæ— æ³•ç»§ç»­è®­ç»ƒ");
                }
            }
        }
    }
}
"

rnn_model.h
"
#ifndef AI3700_RNN_MODEL_H
#define AI3700_RNN_MODEL_H
#include "matrix.h"
#include <vector>
#include <string>
#include <random>

// Adamä¼˜åŒ–å™¨å‚æ•°ç»“æ„ä½“
struct AdamParams {
    Matrix m;  // ä¸€é˜¶çŸ©ä¼°è®¡
    Matrix v;  // äºŒé˜¶çŸ©ä¼°è®¡
    double beta1;
    double beta2;
    double epsilon;

    AdamParams() : beta1(0.9), beta2(0.999), epsilon(1e-8) {}
};

class RNNModel {
public:
    RNNModel(int vocabSize, int hiddenSize, int layers = 2);
    void train(const std::vector<int>& sequence, double learningRate, int epoch);
    int predict(const std::vector<int>& inputSeq, bool random = false, double temperature = 1.0);
    bool save(const std::string& filename);
    bool load(const std::string& filename);
    void selfLearn(int iterations, int seqLen, double lr);

    // è®¾ç½®æ¿€æ´»å‡½æ•°ç±»å‹
    enum ActivationType { TANH, RELU, LEAKY_RELU, SIGMOID };
    void setActivation(ActivationType type) { activationType = type; }

private:
    int vocabSize;  // æ±‰å­—æ€»æ•°
    int hiddenSize; // éšè—å±‚å¤§å°
    int layers;     // å±‚æ•°
    ActivationType activationType; // æ¿€æ´»å‡½æ•°ç±»å‹

    // æƒé‡çŸ©é˜µ
    Matrix Wxh;       // è¾“å…¥â†’éšè— [hiddenSize x vocabSize]
    std::vector<Matrix> Whh;  // éšè—â†’éšè— [hiddenSize x hiddenSize]
    Matrix Why;       // éšè—â†’è¾“å‡º [vocabSize x hiddenSize]
    std::vector<Matrix> bh;   // éšè—å±‚åç½® [hiddenSize x 1]
    Matrix by;        // è¾“å‡ºå±‚åç½® [vocabSize x 1]

    // Adamä¼˜åŒ–å™¨å‚æ•°
    AdamParams optWxh, optWhy;
    std::vector<AdamParams> optWhh, optBh;
    AdamParams optBy;

    // æ–°å¢ï¼šXavieråˆå§‹åŒ–æ–¹æ³•
    void xavierInit(Matrix& m, int fanIn, int fanOut);
    // æ–°å¢ï¼šæ¢¯åº¦è£å‰ª
    void clipGradient(Matrix& grad, double maxNorm);
    // æ–°å¢ï¼šæ£€æŸ¥NaNå€¼
    void checkNaN(const Matrix& m, const std::string& msg);

    struct ForwardCache {
        std::vector<Matrix> h;  // å„å±‚éšè—çŠ¶æ€ [hiddenSize x 1]
        std::vector<Matrix> a;  // å„å±‚æ¿€æ´»å‰çš„å€¼ [hiddenSize x 1]
        Matrix y;               // è¾“å‡º [vocabSize x 1]

        ForwardCache(int layers, int hiddenSize, int vocabSize) {
            h.resize(layers, Matrix(hiddenSize, 1));
            a.resize(layers, Matrix(hiddenSize, 1));
            y = Matrix(vocabSize, 1);
        }
    };

    ForwardCache forward(const std::vector<int>& inputs);
    Matrix activate(const Matrix& m);
    Matrix activateDerivative(const Matrix& m);

    // Adamä¼˜åŒ–æ›´æ–°
    void adamUpdate(Matrix& param, AdamParams& opt, const Matrix& grad, double lr, int t);
};

#endif //AI3700_RNN_MODEL_H
"

start_model.cpp
"
#include "start_model.h"
#include <vector>
#include <string>
#include <queue>
#include <tuple>
#include <algorithm>
#include <iostream>  // å¢åŠ è°ƒè¯•è¾“å‡º

StartModel::StartModel(HanziEncoder& encoder, int hiddenSize, int layers)
        : encoder(encoder), model(encoder.size(), hiddenSize, layers), contextWindow(5) {}

bool StartModel::loadModel(const std::string& path) {
    if (!model.load(path)) {
        std::cerr << "âŒ æ¨¡å‹åŠ è½½å¤±è´¥: " << path << std::endl;
        return false;
    }
    return true;
}

bool StartModel::saveModel(const std::string& path) {
    // æ£€æŸ¥è·¯å¾„æ˜¯å¦æœ‰æ•ˆ
    if (path.empty()) {
        std::cerr << "âŒ æ¨¡å‹è·¯å¾„ä¸ºç©º" << std::endl;
        return false;
    }

    if (!model.save(path)) {
        std::cerr << "âŒ æ¨¡å‹ä¿å­˜å¤±è´¥: " << path << std::endl;
        // å°è¯•å¤‡é€‰è·¯å¾„
        std::string backupPath = "backup_" + path;
        if (model.save(backupPath)) {
            std::cerr << "âš ï¸ å·²ä¿å­˜åˆ°å¤‡é€‰è·¯å¾„: " << backupPath << std::endl;
            return true;
        }
        return false;
    }
    return true;
}

// æ–°å¢ï¼šç›‘æ§è®­ç»ƒè¿‡ç¨‹çš„è¾…åŠ©å‡½æ•°
void printTrainingProgress(int iteration, int total, double loss) {
    if (iteration % 1000 == 0) {
        double progress = static_cast<double>(iteration) / total * 100;
        printf("ğŸ“Š è®­ç»ƒè¿›åº¦: %.1f%% (è¿­ä»£ %d/%d), æŸå¤±: %.6f\n",
               progress, iteration, total, loss);
    }
}

void StartModel::train(int iterations, double lr) {
    // é’ˆå¯¹å¤§éšè—å±‚è°ƒæ•´è®­ç»ƒç­–ç•¥ï¼šå‡å°åˆå§‹å­¦ä¹ ç‡
    double initialLr = lr * 0.5;  // å¯¹äº128éšè—å±‚ï¼Œå­¦ä¹ ç‡å‡åŠ

    try {
        // åˆ†é˜¶æ®µè®­ç»ƒï¼Œå¢åŠ æŸå¤±ç›‘æ§
        for (int i = 0; i < iterations; i++) {
            // åŠ¨æ€è°ƒæ•´åºåˆ—é•¿åº¦ï¼Œé¿å…å†…å­˜æº¢å‡º
            int seqLen = 6 + (i % 3) * 2;  // 6-10ä¹‹é—´åŠ¨æ€è°ƒæ•´

            // ç”Ÿæˆè®­ç»ƒåºåˆ—
            std::vector<int> seq;
            for (int j = 0; j < seqLen; j++) {
                seq.push_back(rand() % encoder.size());
            }

            // è®­ç»ƒä¸€æ­¥å¹¶ç›‘æ§æŸå¤±ï¼ˆç®€åŒ–ç‰ˆæŸå¤±è®¡ç®—ï¼‰
            model.train(seq, initialLr * (1 - i/(double)iterations), i);

            // æ¯1000æ¬¡è¿­ä»£æ‰“å°ä¸€æ¬¡è¿›åº¦
            if (i % 1000 == 0) {
                printTrainingProgress(i, iterations, 0.0);  // å®é™…é¡¹ç›®ä¸­åº”è®¡ç®—çœŸå®æŸå¤±
            }

            // å®šæœŸæ£€æŸ¥æ•°å€¼ç¨³å®šæ€§
            if (i % 5000 == 0 && i > 0) {
                std::cout << "ğŸ” æ£€æŸ¥æ¨¡å‹ç¨³å®šæ€§..." << std::endl;
                // ç”Ÿæˆæµ‹è¯•åºåˆ—éªŒè¯æ¨¡å‹æ˜¯å¦æ­£å¸¸
                std::vector<int> testSeq = {0, 1, 2, 3};  // éšæœºé€‰æ‹©å‡ ä¸ªæ±‰å­—ç´¢å¼•
                int pred = model.predict(testSeq, false);
                if (pred < 0 || pred >= encoder.size()) {
                    std::cerr << "âš ï¸ æ£€æµ‹åˆ°å¼‚å¸¸é¢„æµ‹ï¼Œé‡ç½®å­¦ä¹ ç‡" << std::endl;
                    initialLr *= 0.5;  // é‡åˆ°å¼‚å¸¸æ—¶é™ä½å­¦ä¹ ç‡
                }
            }
        }
    } catch (const std::exception& e) {
        std::cerr << "âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: " << e.what() << std::endl;
        // å°è¯•ä¿å­˜å½“å‰æ¨¡å‹çŠ¶æ€
        saveModel("emergency_model.bin");
    }
}

std::vector<int> StartModel::strToSeq(const std::string& input) {
    std::vector<int> seq;
    for (size_t i = 0; i < input.size();) {
        unsigned char c = (unsigned char)input[i];
        size_t len = 1;

        // åˆ¤æ–­UTF-8å­—ç¬¦é•¿åº¦
        if ((c & 0xF0) == 0xE0) len = 3;  // æ±‰å­—ä¸º3å­—èŠ‚UTF-8
        else if ((c & 0xE0) == 0xC0) len = 2;
        else if (c >= 0x80) { i++; continue; }  // è·³è¿‡æ— æ•ˆå­—ç¬¦

        if (i + len > input.size()) break;

        std::string hanzi = input.substr(i, len);
        i += len;

        int code = encoder.encode(hanzi);
        if (code != -1) {
            seq.push_back(code);
        }
    }
    return seq;
}

std::string StartModel::seqToStr(const std::vector<int>& seq) {
    std::string s;
    for (int code : seq) {
        s += encoder.decode(code);
    }
    return s;
}

std::vector<int> StartModel::beamSearch(const std::vector<int>& inputSeq, int length,
                                        int beamWidth, double temperature) {
    // é™åˆ¶beamWidthå¤§å°ï¼Œé¿å…å†…å­˜å ç”¨è¿‡é«˜
    beamWidth = std::min(beamWidth, 5);  // å¯¹äºå¤§æ¨¡å‹ï¼Œå‡å°beamWidth

    std::vector<std::pair<std::vector<int>, double>> beams;
    beams.emplace_back(inputSeq, 0.0);

    for (int i = 0; i < length; i++) {
        std::vector<std::pair<std::vector<int>, double>> newBeams;

        for (const auto& beam : beams) {
            const std::vector<int>& seq = beam.first;
            double score = beam.second;

            std::vector<int> context = seq;
            if ((int)context.size() > contextWindow) {
                context = std::vector<int>(context.end() - contextWindow, context.end());
            }

            // å‡å°‘å€™é€‰æ•°é‡ï¼Œé™ä½è®¡ç®—é‡
            std::vector<std::pair<int, double>> candidates;
            int candidateCount = std::min(beamWidth * 2, encoder.size() / 2);
            for (int j = 0; j < candidateCount; j++) {
                int next = model.predict(context, true, temperature);
                candidates.emplace_back(next, -j);
            }

            for (const auto& cand : candidates) {
                std::vector<int> newSeq = seq;
                newSeq.push_back(cand.first);
                newBeams.emplace_back(newSeq, score + cand.second);
            }
        }

        std::sort(newBeams.begin(), newBeams.end(),
                  [](const std::pair<std::vector<int>, double>& a,
                     const std::pair<std::vector<int>, double>& b) {
                      return a.second > b.second;
                  });

        if ((int)newBeams.size() > beamWidth) {
            newBeams.resize(beamWidth);
        }

        beams = newBeams;

        // é˜²æ­¢ç©ºå…‰æŸ
        if (beams.empty()) {
            std::cerr << "âš ï¸ å…‰æŸæœç´¢ä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹åºåˆ—" << std::endl;
            return inputSeq;
        }
    }

    return beams[0].first;
}

std::string StartModel::generateResponse(const std::string& input, int length,
                                         double temperature, bool random) {
    // é™åˆ¶ç”Ÿæˆé•¿åº¦ï¼Œé¿å…å†…å­˜æº¢å‡º
    length = std::min(length, 20);  // å¯¹äºå¤§æ¨¡å‹ï¼Œå‡å°‘ç”Ÿæˆé•¿åº¦

    std::vector<int> inputSeq = strToSeq(input);
    if (inputSeq.empty()) return "æœªè¯†åˆ«åˆ°æœ‰æ•ˆæ±‰å­—";

    try {
        std::vector<int> outputSeq;

        if (length > 10) {
            outputSeq = beamSearch(inputSeq, length, 3, temperature);  // è¿›ä¸€æ­¥å‡å°beamWidth
        } else {
            outputSeq = inputSeq;
            std::vector<int> context = inputSeq;

            for (int i = 0; i < length; i++) {
                if ((int)context.size() > contextWindow) {
                    context = std::vector<int>(context.end() - contextWindow, context.end());
                }

                int next = model.predict(context, random, temperature);
                outputSeq.push_back(next);
                context.push_back(next);
            }
        }

        return seqToStr(outputSeq);
    } catch (const std::exception& e) {
        std::cerr << "âŒ ç”Ÿæˆå“åº”æ—¶å‡ºé”™: " << e.what() << std::endl;
        return "ç”Ÿæˆå“åº”å¤±è´¥ï¼Œè¯·é‡è¯•";
    }
}
"

start_model.h
"
#ifndef AI3700_START_MODEL_H
#define AI3700_START_MODEL_H
#include "rnn_model.h"
#include "hanzi_encoder.h"
#include <string>
#include <vector>

class StartModel {
public:
    StartModel(HanziEncoder& encoder, int hiddenSize = 128, int layers = 2);
    bool loadModel(const std::string& path);
    bool saveModel(const std::string& path);
    void train(int iterations = 50000, double lr = 0.001);
    std::string generateResponse(const std::string& input, int length = 20,
                                 double temperature = 0.7, bool random = true);

    // è®¾ç½®æ¨¡å‹å‚æ•°
    void setContextWindow(int window) { contextWindow = window; }
    void setActivation(RNNModel::ActivationType type) { model.setActivation(type); }

private:
    HanziEncoder& encoder;
    RNNModel model;
    int contextWindow; // ä¸Šä¸‹æ–‡çª—å£å¤§å°

    std::vector<int> strToSeq(const std::string& input);
    std::string seqToStr(const std::vector<int>& seq);

    // ä½¿ç”¨beam searchæé«˜ç”Ÿæˆè´¨é‡
    std::vector<int> beamSearch(const std::vector<int>& inputSeq, int length,
                                int beamWidth = 5, double temperature = 1.0);
};

#endif //AI3700_START_MODEL_H
"