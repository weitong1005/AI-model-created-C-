"
AI3700/
├── CMakeLists.txt
├── data
│   └── hanzi.txt
├── main.cpp
├── model
└── src
    ├── file_utils.cpp
    ├── file_utils.h
    ├── hanzi_encoder.cpp
    ├── hanzi_encoder.h
    ├── matrix.cpp
    ├── matrix.h
    ├── rnn_model.cpp
    ├── rnn_model.h
    ├── start_model.cpp
    └── start_model.h

"

CMakeLists.txt
"
cmake_minimum_required(VERSION 3.10)
project(AI3700)
set(CMAKE_CXX_STANDARD 11)
set(CMAKE_CXX_STANDARD_REQUIRED ON)

# 确保中文正常处理
add_compile_options(-finput-charset=UTF-8)
include_directories(src)

add_executable(AI3700
        main.cpp
        src/file_utils.cpp
        src/file_utils.h
        src/hanzi_encoder.cpp
        src/hanzi_encoder.h
        src/matrix.cpp
        src/matrix.h
        src/rnn_model.cpp
        src/rnn_model.h
        src/start_model.cpp
        src/start_model.h
)

# 针对不同平台的特定设置
if(WIN32)
    # Windows 特定设置
    target_compile_definitions(AI3700 PRIVATE _CRT_SECURE_NO_WARNINGS)
elseif(UNIX)
    # Linux 特定设置
    target_compile_options(AI3700 PRIVATE -Wall -Wextra)
endif()

# 自动复制 hanzi.txt 到构建目录
add_custom_command(
        TARGET AI3700 POST_BUILD
        COMMAND ${CMAKE_COMMAND} -E copy_if_different
        ${CMAKE_SOURCE_DIR}/data/hanzi.txt
        $<TARGET_FILE_DIR:AI3700>
)
"
hanzi.txt
"
a: 阿啊哎哀唉埃挨癌矮蔼爱碍安岸按案暗昂凹熬傲奥澳腌吖锕嗄
ba: 八巴扒吧疤拔跋把坝爸罢霸掰白百柏摆败拜斑班搬板版办半伴扮瓣邦帮膀傍棒包胞雹宝饱保堡报抱暴爆杯悲碑北贝备背倍被辈奔本笨崩绷蹦逼鼻比彼笔鄙币必毕闭庇毙秘弊碧蔽壁避臂边编鞭扁便变遍辨辩辫标彪膘表憋别宾滨冰兵丙柄饼并病拨波玻剥脖菠伯驳泊博搏膊薄卜补捕不布步怖部魃粑笆钯
cai: 猜才材财裁采彩睬踩菜参餐残蚕惭惨灿仓苍舱藏操糙槽草册侧厕测策层曾叉插查察茬茶搽差拆柴豺搀掺馋缠蝉产铲阐颤昌长肠尝常偿厂场敞畅倡唱抄钞超巢朝嘲潮吵炒车扯彻撤尘臣沉辰陈晨闯衬称趁撑成呈诚承城乘惩程澄橙逞秤吃痴持池迟驰耻齿斥赤翅充冲虫崇宠抽仇绸愁稠筹酬丑臭出初除厨锄础储楚处触川穿传船喘串疮窗床创吹炊垂锤春纯唇淳醇蠢戳绰词祠慈辞磁雌此次刺赐匆葱聪从丛凑粗促醋簇窜篡催摧脆粹翠村存寸搓措错偲骖粲
da: 搭达答打大呆歹代带待怠贷袋逮戴丹单担耽胆旦但诞弹淡蛋当挡党荡档刀叨导岛倒蹈到悼盗道稻得德的灯登等瞪凳低堤滴迪敌笛底抵地弟帝递第颠典点电佃店垫淀殿刁叼雕吊钓调掉爹跌叠蝶丁叮盯钉顶订定丢东冬董懂动冻栋洞都兜抖斗陡豆逗都督毒读独堵赌杜肚度渡端短段断缎煅锻堆队对兑吨敦蹲盾顿多夺朵躲耷哒嗒鞑
e: 俄鹅额恶饿遏恩儿而尔耳二贰婀轭迩
fa: 发乏伐罚阀筏法帆番翻凡烦繁反返犯饭泛范贩方坊芳防妨房仿访纺放飞非啡肥匪诽吠肺废沸费分芬吩纷氛坟焚粉份奋愤粪丰风封疯峰锋蜂逢缝讽凤奉佛否夫敷肤伏扶拂服俘浮符幅福抚甫府斧俯辅腐父付负妇附咐复赴副傅富腹覆砝
ga: 尬该改盖概钙干甘杆肝竿秆赶敢感干冈刚纲缸钢岗港杠高膏篙糕搞稿告哥歌搁割革葛格隔个各给根跟更耕工弓公功攻供宫恭躬巩拱共贡勾沟钩狗构购够估咕孤姑古谷股骨鼓固故顾雇瓜刮挂乖拐怪关观官冠棺馆管贯惯灌罐光广归龟规闺轨鬼柜贵桂跪滚棍国果过尕旮
ha: 哈孩海害酣含函寒喊罕汉汗旱悍焊憾撼行航巷毫豪好号浩耗呵喝合何和河核荷盒贺黑嘿痕很狠恨哼恒横衡轰哄烘红宏洪虹鸿侯喉猴吼后厚候乎呼忽狐胡壶湖糊虎互户护花华哗滑猾化划画话怀槐坏欢还环缓幻唤换患焕疾豢慌皇黄煌晃谎灰挥恢辉回毁悔汇会讳绘贿秽惠慧昏婚浑魂混豁活火伙或货获祸惑铪氦劾
ji: 击饥圾机肌鸡迹积基绩激及吉级即极急疾集籍几己挤脊计记纪忌技际剂季既济继寄寂加夹佳家嘉甲钾价驾架假嫁稼奸尖坚间肩艰兼监煎拣俭柬捡检减剪简见件建剑荐贱健舰渐溅鉴键箭江将姜浆僵疆讲奖匠降酱交郊浇骄娇胶教焦嚼角狡脚搅缴叫轿较觉阶皆接揭街节劫杰洁结捷截竭姐解介戒届界借巾斤今金津筋仅紧锦谨尽劲近进晋浸禁京经茎惊晶睛精井颈景警净径竞竟敬境静镜纠究九久酒旧救就舅居拘鞠局菊橘举矩句巨拒具剧惧据距锯聚捐卷倦绢决绝觉掘嚼军君均菌俊峻骏丌乩剞掎彐麂
ka: 咖卡开揩凯慨刊堪砍看康慷糠扛抗炕考烤靠科棵颗壳咳可渴克刻客课肯垦恳坑空孔恐控抠口扣枯哭苦库裤酷夸跨挎块快宽款匡筐狂况矿框旷亏窥葵魁愧溃昆困括阔咔佧胩
la: 垃拉啦喇腊蜡辣来莱赖蓝栏拦篮览懒烂滥郎狼廊朗浪捞劳牢老佬姥涝乐勒雷垒泪类累冷厘梨离璃黎礼李里理鲤力历厉立丽利励例隶俩连帘怜莲联廉脸练炼恋链良凉梁粮两亮谅辆量辽疗聊僚了料列劣烈猎裂邻林临淋磷灵铃陵零龄领令另溜刘留流硫榴柳六龙聋隆垄拢笼弄楼搂漏露卢芦炉鲁陆录鹿碌路驴旅屡律虑绿滤剌邋旯
ma: 妈麻马玛码蚂骂吗埋买麦卖迈脉瞒满曼慢漫忙芒盲茫猫毛矛茅茂冒贸帽貌么没眉梅媒煤霉每美妹门闷们萌盟猛梦眯弥迷谜米秘觅密蜜眠绵棉免勉面苗描瞄秒妙庙灭民敏名明鸣命谬摸模膜摩磨抹末没莫墨默谋某母亩牡姆拇木目牧墓幕慕暮穆祃犸杩
na: 拿哪那纳钠乃奶耐男南难囊挠恼脑闹呢内嫩能妮泥你拟逆年念娘酿鸟尿捏您宁凝牛扭纽农浓弄奴努怒女暖虐挪诺捺肭衲
ou: 欧鸥殴偶藕呕沤耦怄瓯
pa: 趴爬帕怕拍排牌派攀盘判叛盼乓庞旁胖抛炮袍跑泡呸陪培赔佩配喷盆砰抨烹朋棚蓬硼鹏捧碰批披劈皮疲匹痞僻屁譬片偏篇骗飘漂票撇拼贫频品聘乒平评凭苹瓶萍坡泼婆迫破魄剖扑铺仆葡朴普谱瀑筢
qi: 七妻凄戚期欺漆齐其奇歧骑棋旗乞企岂启起气迄弃汽契砌器恰洽千迁牵铅谦签前钱钳潜浅遣欠款枪腔强墙抢悄敲锹桥瞧巧切茄且窃亲侵芹琴禽勤青氢轻倾清情晴顷请庆穷丘秋求球区曲驱屈趋渠取娶去趣圈权全泉拳犬劝券缺却雀确鹊俟汔碛葺
ran: 然燃染嚷壤让饶扰绕惹热人仁忍认任扔仍日绒荣容熔融冗柔揉肉如儒乳辱入软锐瑞润若弱苒蚺髯
sa: 撒洒萨塞赛三散桑嗓丧搔骚扫嫂色涩森僧杀沙纱傻啥筛晒山删衫闪陕扇善伤商裳晌赏上尚捎梢烧稍勺少哨舌蛇舍设社射涉摄申伸身深神审婶肾甚渗慎升生声性牲胜绳省圣盛剩尸失师诗施狮湿十石时识实拾蚀食史使始驶士氏世示市式似事势侍饰试视柿是适室逝释收手守首寿受兽售授瘦书叔殊梳疏舒输蔬熟暑属鼠数术束述树竖恕刷衰摔甩帅栓双霜爽谁水税睡顺说司丝私思斯撕死四寺似饲肆松宋送诵搜艘苏俗诉肃素速宿塑酸蒜算虽随岁碎穗孙损笋缩所索锁卅挲脎
ta: 他它她塌塔踏台抬太态泰贪摊滩坛谈痰潭坦叹炭探叹汤唐堂塘膛糖倘躺趟涛掏滔逃桃陶淘讨套特藤腾疼梯踢啼提题蹄体替天添田甜填挑条跳贴铁厅听烃廷亭庭停挺艇通同铜童统痛偷头投透凸秃突图徒途涂屠土吐兔团推腿退吞屯托拖脱驼妥拓唾溻獭鳎
wa: 挖哇蛙娃瓦歪外弯湾丸完玩顽挽晚碗万汪亡王网往忘旺望危威微为围违唯维伟韦伪尾纬委萎卫未位味畏胃喂慰温文纹闻蚊稳问翁嗡窝我沃卧握乌污屋无吴吾五午伍武侮舞务物误悟雾腽娲畖
xi: 夕西吸希昔析息牺悉惜稀溪锡熄熙蜥嘻膝习席袭媳洗喜戏系细隙虾瞎峡狭霞下夏吓仙先纤掀鲜闲弦咸衔嫌显险县现限线宪陷馅羡献乡相香厢湘箱详祥翔享响想向巷项象像橡削消宵萧销小晓孝校笑效些歇协邪胁斜谐携鞋写泄泻卸屑械谢心辛欣新薪信兴星腥刑行形型醒杏姓幸性兄凶胸匈雄熊休修羞朽秀绣袖须虚需徐许序叙畜绪续酗蓄宣悬旋玄选穴学雪血勋寻巡询循训讯迅葸舄禊
ya: 压押鸦鸭牙芽崖哑亚讶咽烟淹延严言岩沿炎研盐颜檐衍掩眼演厌宴艳验焰雁燕央殃秧扬羊阳杨洋仰养氧痒样腰邀摇遥咬药要耀爷也冶野业叶页夜液一伊衣医依仪夷宜姨移遗疑乙已以矣蚁倚椅义亿忆艺议亦异役抑译易疫益谊意溢毅翼因阴音姻银引饮隐印应英婴樱鹰迎盈营蝇赢影映硬哟拥佣永咏泳勇用优忧幽悠尤由邮犹油游友有又右幼诱于予余鱼娱渔愉愚与宇羽雨语玉育郁狱浴预域欲遇御裕愈誉冤元员园原圆援缘源远怨院愿曰约月悦阅跃越云匀允运孕蚜睚痖
za: 杂灾栽宰载再在咱攒暂赞赃脏葬遭糟早枣澡藻灶皂造噪燥躁则择泽责贼怎增赠渣扎轧眨炸摘宅窄债沾粘展占战站张章涨掌丈仗帐胀障招找召兆赵照遮折哲者这浙珍真诊阵振镇震争征挣睁蒸整正证郑政症之支汁芝枝知肢织脂蜘执直值职植殖止只旨址纸指趾至志制帜治质秩致智置中忠终钟肿种仲众重州舟周洲粥轴宙昼皱骤朱珠株诸猪蛛竹烛逐主属煮嘱住助注贮驻柱祝著筑抓爪拽专砖转赚庄装壮状撞追准捉桌着仔兹姿资滋籽子紫字自宗综棕踪总纵走奏租足族阻组祖钻嘴最罪醉尊遵昨左作坐座做匝拶咂

# 补充汉字以满足3700个
beng: 崩绷泵蹦迸甭嘣
............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
"

main.cpp

"
#include "hanzi_encoder.h"
#include "file_utils.h"
#include "start_model.h"
#include <iostream>
#include <sys/stat.h>
#include <sys/types.h>
#include <string>
#include <chrono>

#ifdef _WIN32
#include <direct.h>
#else
#include <unistd.h>
#endif

bool createDirectory(const std::string& path) {
#ifdef _WIN32
    return _mkdir(path.c_str()) == 0;
#else
    mode_t mode = 0755;
    return mkdir(path.c_str(), mode) == 0;
#endif
}

bool fileExists(const std::string& path) {
    struct stat buffer;
    return (stat(path.c_str(), &buffer) == 0);
}

int main() {
    auto startTime = std::chrono::high_resolution_clock::now();

    HanziEncoder encoder;
    std::cout << "📖 加载汉字库...\n";
    if (!encoder.loadFromFile("hanzi.txt")) {
        std::cerr << "❌ 汉字库加载失败，请确保hanzi.txt在当前目录\n";
        return 1;
    }
    std::cout << "✅ 加载 " << encoder.size() << " 个汉字\n";

    std::string modelDir = "model";
    if (!fileExists(modelDir) && !createDirectory(modelDir)) {
        std::cerr << "❌ 无法创建模型目录: " << modelDir << "\n";
        modelDir = ".";
        std::cout << "⚠️ 改用当前目录存储模型\n";
    }


    try {
        // 递减隐藏层大小至8，层数保持2
        int hiddenSize = 1;
        int layers = 1000;
        StartModel model(encoder, hiddenSize, layers);
        model.setContextWindow(3);  // 进一步减小上下文窗口
        model.setActivation(RNNModel::TANH);  // Tanh更稳定，适合小模型

        std::string modelPath = modelDir + "/model.bin";
        if (!fileExists(modelPath)) {
            std::cout << "\n⏳ 首次运行，开始训练模型...\n";
            std::cout << "💡 模型配置: 隐藏层大小=" << hiddenSize << ", 层数=" << layers << "\n";

            // 小模型可以适当增加迭代次数
            int iterations = 20000;
            model.train(iterations, 0.0001);

            std::cout << "💾 保存模型...\n";
            if (!model.saveModel(modelPath)) {
                std::cerr << "❌ 模型保存失败！\n";
                return 1;
            } else {
                std::cout << "✅ 模型保存至 " << modelPath << "\n";
            }
        } else {
            std::cout << "\n📂 加载已有模型...\n";
            if (!model.loadModel(modelPath)) {
                std::cerr << "❌ 模型加载失败，尝试重新训练...\n";
                model.train(5000, 0.0001);
                model.saveModel(modelPath);
            }
        }

        auto endTime = std::chrono::high_resolution_clock::now();
        std::chrono::duration<double> elapsed = endTime - startTime;
        std::cout << "\n⏱️  模型准备时间: " << elapsed.count() << " 秒\n";

        std::cout << "\n💬 模型就绪，输入q退出\n";
        std::string input;
        while (true) {
            std::cout << "你: ";
            std::getline(std::cin, input);
            if (input == "q") break;

            std::string response = model.generateResponse(input, 8, 0.5, true);
            std::cout << "AI: " << response << "\n\n";
        }
    } catch (const std::bad_alloc& e) {
        std::cerr << "\n❌ 内存分配失败！尝试更小的隐藏层（4）\n";
        return 1;
    } catch (const std::exception& e) {
        std::cerr << "\n❌ 程序错误: " << e.what() << "\n";
        return 1;
    }

    return 0;
}
"

file_utils.cpp
"
#include "file_utils.h"
#include <fstream>

bool FileUtils::generateDataFiles(const HanziEncoder& encoder,
                                  const std::string& dataFile,
                                  const std::string& codeFile) {
    // 生成数据文件
    std::ofstream dataOut(dataFile, std::ios::binary);
    if (!dataOut) return false;

    int count = encoder.size();
    dataOut.write(reinterpret_cast<const char*>(&count), sizeof(count));

    for (int i = 0; i < count; ++i) {
        std::string hanzi = encoder.decode(i);
        int len = hanzi.size();
        dataOut.write(reinterpret_cast<const char*>(&len), sizeof(len));
        dataOut.write(hanzi.data(), len);
    }
    dataOut.close();

    // 生成编码文件
    std::ofstream codeOut(codeFile, std::ios::binary);
    if (!codeOut) return false;

    codeOut.write(reinterpret_cast<const char*>(&count), sizeof(count));
    for (int i = 0; i < count; ++i) {
        std::string hanzi = encoder.decode(i);
        int len = hanzi.size();
        codeOut.write(reinterpret_cast<const char*>(&len), sizeof(len));
        codeOut.write(hanzi.data(), len);
        codeOut.write(reinterpret_cast<const char*>(&i), sizeof(i));
    }
    codeOut.close();

    return true;
}

// loadFromDataFiles 实现保持不变
"

file_utils.h
"
#ifndef AI3700_FILE_UTILS_H
#define AI3700_FILE_UTILS_H

#include "hanzi_encoder.h"
#include <string>

class FileUtils {
public:
    static bool generateDataFiles(const HanziEncoder& encoder,
                                  const std::string& dataFile = "hanzi_data.bin",
                                  const std::string& codeFile = "hanzi_codes.bin");

    static bool loadFromDataFiles(HanziEncoder& encoder,
                                  const std::string& dataFile = "hanzi_data.bin",
                                  const std::string& codeFile = "hanzi_codes.bin");
};

#endif
"

hanzi_encoder.cpp
"
#include "hanzi_encoder.h"
#include <fstream>
#include <iostream>
#include <cctype>
#include <algorithm>

void HanziEncoder::clear() {
    hanziToId.clear();
    idToHanzi.clear();
}

bool HanziEncoder::loadFromFile(const std::string& filename) {
    clear();
    std::ifstream infile(filename);
    if (!infile) {
        std::cerr << "无法打开文件: " << filename << std::endl;
        return false;
    }

    std::string line;
    int totalAdded = 0;
    int lineNumber = 0;

    while (std::getline(infile, line)) {
        lineNumber++;
        if (line.empty()) continue;

        // 提取汉字部分（跳过拼音）
        size_t pos = line.find(':');
        if (pos == std::string::npos) continue;

        std::string hanziBlock = line.substr(pos + 1);

        // 移除所有空格和星号
        hanziBlock.erase(std::remove_if(hanziBlock.begin(), hanziBlock.end(),
                                        [](char c) { return std::isspace(static_cast<unsigned char>(c)) || c == '*'; }),
                         hanziBlock.end());

        // 处理连续UTF-8字符
        for (size_t i = 0; i < hanziBlock.size();) {
            int len = 0;
            unsigned char c = static_cast<unsigned char>(hanziBlock[i]);

            if (c < 0x80) {
                len = 1;  // ASCII字符
            } else if ((c & 0xE0) == 0xC0) {
                len = 2;  // 2字节UTF-8
            } else if ((c & 0xF0) == 0xE0) {
                len = 3;  // 3字节UTF-8（大多数汉字）
            } else if ((c & 0xF8) == 0xF0) {
                len = 4;  // 4字节UTF-8
            } else {
                i++;  // 跳过无效字节
                continue;
            }

            if (i + len > hanziBlock.size()) break;

            std::string hanzi = hanziBlock.substr(i, len);
            i += len;

            // 添加到编码器
            if (hanziToId.find(hanzi) == hanziToId.end()) {
                hanziToId[hanzi] = idToHanzi.size();
                idToHanzi.push_back(hanzi);
                totalAdded++;
            }
        }
    }

    std::cout << "成功加载 " << totalAdded << " 个汉字\n";
    return true;
}

int HanziEncoder::encode(const std::string& hanzi) const {
    auto it = hanziToId.find(hanzi);
    return (it != hanziToId.end()) ? it->second : -1;
}

std::string HanziEncoder::decode(int code) const {
    return (code >= 0 && code < static_cast<int>(idToHanzi.size())) ? idToHanzi[code] : "";
}

int HanziEncoder::size() const {
    return static_cast<int>(idToHanzi.size());
}
"

hanzi_encoder.h
"
#ifndef AI3700_HANZI_ENCODER_H
#define AI3700_HANZI_ENCODER_H

#include <string>
#include <unordered_map>
#include <vector>

class HanziEncoder {
public:
    bool loadFromFile(const std::string& filename);
    int encode(const std::string& hanzi) const;
    std::string decode(int code) const;
    int size() const;
    void clear();

private:
    std::unordered_map<std::string, int> hanziToId;
    std::vector<std::string> idToHanzi;
};

#endif
"

matrix.cpp
"
#include "matrix.h"
#include <cstdlib>
#include <ctime>

Matrix::Matrix(int rows, int cols, bool random) : rows(rows), cols(cols) {
    data.resize(rows, std::vector<double>(cols, 0.0));
    if (random) {
        std::srand(std::time(nullptr));
        randomize();
    }
}

Matrix::Matrix(const std::vector<std::vector<double>>& initData)
        : data(initData), rows(initData.size()), cols(initData[0].size()) {}

Matrix Matrix::operator+(const Matrix& other) const {
    if (rows != other.rows || cols != other.cols) {
        std::cerr << "矩阵加法维度不匹配: (" << rows << "x" << cols
                  << ") + (" << other.rows << "x" << other.cols << ")\n";
        return Matrix();
    }

    Matrix result(rows, cols);
    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            result.data[i][j] = data[i][j] + other.data[i][j];
    return result;
}

Matrix Matrix::operator-(const Matrix& other) const {
    if (rows != other.rows || cols != other.cols) {
        std::cerr << "矩阵减法维度不匹配: (" << rows << "x" << cols
                  << ") - (" << other.rows << "x" << other.cols << ")\n";
        return Matrix();
    }

    Matrix result(rows, cols);
    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            result.data[i][j] = data[i][j] - other.data[i][j];
    return result;
}

Matrix Matrix::operator*(const Matrix& other) const {
    if (cols != other.rows) {
        std::cerr << "致命错误：矩阵乘法维度不匹配 (" << rows << "x" << cols
                  << ") * (" << other.rows << "x" << other.cols << ")\n";
        std::exit(1);
    }

    Matrix result(rows, other.cols);
    for (int i = 0; i < rows; i++) {
        for (int k = 0; k < cols; k++) {
            if (data[i][k] == 0) continue;
            for (int j = 0; j < other.cols; j++) {
                result.data[i][j] += data[i][k] * other.data[k][j];
            }
        }
    }
    return result;
}

Matrix Matrix::operator*(double scalar) const {
    Matrix result(rows, cols);
    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            result.data[i][j] = data[i][j] * scalar;
    return result;
}

Matrix Matrix::operator/(double scalar) const {
    Matrix result(rows, cols);
    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            result.data[i][j] = data[i][j] / scalar;
    return result;
}

Matrix& Matrix::operator+=(const Matrix& other) {
    if (rows != other.rows || cols != other.cols) {
        std::cerr << "矩阵加法维度不匹配\n";
        return *this;
    }

    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            data[i][j] += other.data[i][j];
    return *this;
}

Matrix& Matrix::operator-=(const Matrix& other) {
    if (rows != other.rows || cols != other.cols) {
        std::cerr << "矩阵减法维度不匹配\n";
        return *this;
    }

    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            data[i][j] -= other.data[i][j];
    return *this;
}

Matrix& Matrix::operator*=(double scalar) {
    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            data[i][j] *= scalar;
    return *this;
}

Matrix Matrix::transpose() const {
    Matrix result(cols, rows);
    for (int i = 0; i < rows; i++) {
        for (int j = 0; j < cols; j++) {
            result.data[j][i] = data[i][j];
        }
    }
    return result;
}

Matrix Matrix::sigmoid(const Matrix& m) {
    Matrix result(m.rows, m.cols);
    for (int i = 0; i < m.rows; i++)
        for (int j = 0; j < m.cols; j++)
            result.data[i][j] = 1.0 / (1.0 + exp(-m.data[i][j]));
    return result;
}

Matrix Matrix::sigmoidDerivative(const Matrix& m) {
    Matrix s = sigmoid(m);
    Matrix result(m.rows, m.cols);
    for (int i = 0; i < m.rows; i++)
        for (int j = 0; j < m.cols; j++)
            result.data[i][j] = s.data[i][j] * (1 - s.data[i][j]);
    return result;
}

Matrix Matrix::tanh(const Matrix& m) {
    Matrix result(m.rows, m.cols);
    for (int i = 0; i < m.rows; i++)
        for (int j = 0; j < m.cols; j++)
            result.data[i][j] = std::tanh(m.data[i][j]);
    return result;
}

Matrix Matrix::tanhDerivative(const Matrix& m) {
    Matrix result(m.rows, m.cols);
    for (int i = 0; i < m.rows; i++)
        for (int j = 0; j < m.cols; j++) {
            double t = std::tanh(m.data[i][j]);
            result.data[i][j] = 1 - t * t;
        }
    return result;
}

Matrix Matrix::relu(const Matrix& m) {
    Matrix result(m.rows, m.cols);
    for (int i = 0; i < m.rows; i++)
        for (int j = 0; j < m.cols; j++)
            result.data[i][j] = std::max(0.0, m.data[i][j]);
    return result;
}

Matrix Matrix::reluDerivative(const Matrix& m) {
    Matrix result(m.rows, m.cols);
    for (int i = 0; i < m.rows; i++)
        for (int j = 0; j < m.cols; j++)
            result.data[i][j] = (m.data[i][j] > 0) ? 1.0 : 0.0;
    return result;
}

Matrix Matrix::leakyRelu(const Matrix& m, double alpha) {
    Matrix result(m.rows, m.cols);
    for (int i = 0; i < m.rows; i++)
        for (int j = 0; j < m.cols; j++)
            result.data[i][j] = std::max(alpha * m.data[i][j], m.data[i][j]);
    return result;
}

Matrix Matrix::leakyReluDerivative(const Matrix& m, double alpha) {
    Matrix result(m.rows, m.cols);
    for (int i = 0; i < m.rows; i++)
        for (int j = 0; j < m.cols; j++)
            result.data[i][j] = (m.data[i][j] > 0) ? 1.0 : alpha;
    return result;
}

void Matrix::randomize(double min, double max) {
    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            data[i][j] = min + (max - min) * ((double)rand() / RAND_MAX);
}

void Matrix::zeros() {
    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            data[i][j] = 0.0;
}

void Matrix::ones() {
    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
            data[i][j] = 1.0;
}
"

matrix.h
"
#ifndef AI3700_MATRIX_H
#define AI3700_MATRIX_H
#include <vector>
#include <iostream>
#include <cmath>

class Matrix {
public:
    std::vector<std::vector<double>> data;
    int rows;
    int cols;

    Matrix() : rows(0), cols(0) {}
    Matrix(int rows, int cols, bool random = false);
    Matrix(const std::vector<std::vector<double>>& initData);

    // 矩阵运算
    Matrix operator+(const Matrix& other) const;
    Matrix operator-(const Matrix& other) const;
    Matrix operator*(const Matrix& other) const;
    Matrix operator*(double scalar) const;
    Matrix operator/(double scalar) const;
    Matrix& operator+=(const Matrix& other);
    Matrix& operator-=(const Matrix& other);
    Matrix& operator*=(double scalar);

    Matrix transpose() const;

    // 激活函数
    static Matrix sigmoid(const Matrix& m);
    static Matrix sigmoidDerivative(const Matrix& m);
    static Matrix tanh(const Matrix& m);
    static Matrix tanhDerivative(const Matrix& m);
    static Matrix relu(const Matrix& m);
    static Matrix reluDerivative(const Matrix& m);
    static Matrix leakyRelu(const Matrix& m, double alpha = 0.01);
    static Matrix leakyReluDerivative(const Matrix& m, double alpha = 0.01);

    // 辅助函数
    void randomize(double min = -0.5, double max = 0.5);
    void zeros();
    void ones();
    void printDimensions(const std::string& name) const {
        std::cout << name << " dimensions: " << rows << "x" << cols << std::endl;
    }
};

#endif //AI3700_MATRIX_H
"

rnn_model.cpp
"
#include "rnn_model.h"
#include <fstream>
#include <cmath>
#include <iostream>
#include <random>
#include <stdexcept>

// 添加NaN检查函数
bool isNaN(double x) {
    return x != x;
}

// 添加梯度裁剪函数
void clipGradients(Matrix& grad, double maxNorm) {
    double norm = 0.0;
    for (int i = 0; i < grad.rows; i++) {
        for (int j = 0; j < grad.cols; j++) {
            norm += grad.data[i][j] * grad.data[i][j];
        }
    }
    norm = sqrt(norm);

    if (norm > maxNorm && norm > 0) {
        double scale = maxNorm / norm;
        grad *= scale;
    }
}

RNNModel::RNNModel(int vocabSize, int hiddenSize, int layers)
        : vocabSize(vocabSize), hiddenSize(hiddenSize), layers(layers), activationType(TANH) {
    // 改进权重初始化：使用Xavier初始化，解决初始值过大问题
    double wxhScale = sqrt(1.0 / vocabSize);
    Wxh = Matrix(hiddenSize, vocabSize, true);
    Wxh *= wxhScale;  // 根据输入维度缩放

    Whh.resize(layers);
    double whhScale = sqrt(1.0 / hiddenSize);
    for (int i = 0; i < layers; i++) {
        Whh[i] = Matrix(hiddenSize, hiddenSize, true);
        Whh[i] *= whhScale;  // 根据隐藏层维度缩放
    }

    double whyScale = sqrt(1.0 / hiddenSize);
    Why = Matrix(vocabSize, hiddenSize, true);
    Why *= whyScale;

    // 偏置初始化为较小的常数，避免初始为0
    bh.resize(layers, Matrix(hiddenSize, 1));
    for (int i = 0; i < layers; i++) {
        for (int j = 0; j < hiddenSize; j++) {
            bh[i].data[j][0] = 0.01;  // 小的正值初始化
        }
    }

    by = Matrix(vocabSize, 1);
    for (int i = 0; i < vocabSize; i++) {
        by.data[i][0] = 0.01;
    }

    // 初始化Adam优化器参数
    optWxh.m = Matrix(hiddenSize, vocabSize);
    optWxh.v = Matrix(hiddenSize, vocabSize);
    optWhy.m = Matrix(vocabSize, hiddenSize);
    optWhy.v = Matrix(vocabSize, hiddenSize);

    optWhh.resize(layers);
    optBh.resize(layers);
    for (int i = 0; i < layers; i++) {
        optWhh[i].m = Matrix(hiddenSize, hiddenSize);
        optWhh[i].v = Matrix(hiddenSize, hiddenSize);
        optBh[i].m = Matrix(hiddenSize, 1);
        optBh[i].v = Matrix(hiddenSize, 1);
    }

    optBy.m = Matrix(vocabSize, 1);
    optBy.v = Matrix(vocabSize, 1);
}

Matrix RNNModel::activate(const Matrix& m) {
    // 激活函数输出后检查并处理NaN
    Matrix result = Matrix::leakyRelu(m);  // Leaky ReLU更不容易出现死亡神经元

    // 检查并替换NaN值
    for (int i = 0; i < result.rows; i++) {
        for (int j = 0; j < result.cols; j++) {
            if (isNaN(result.data[i][j])) {
                result.data[i][j] = 0.01;  // 用小值替换NaN
            }
        }
    }

    return result;
}

Matrix RNNModel::activateDerivative(const Matrix& m) {
    return Matrix::leakyReluDerivative(m);
}

// 改进的softmax函数，添加数值稳定处理
Matrix softmax(const Matrix& m) {
    Matrix result(m.rows, m.cols);
    double maxVal = m.data[0][0];

    // 找到最大值，用于数值稳定
    for (int i = 0; i < m.rows; i++) {
        if (m.data[i][0] > maxVal) {
            maxVal = m.data[i][0];
        }
    }

    // 计算指数并减去最大值防止溢出
    double sum = 0.0;
    for (int i = 0; i < m.rows; i++) {
        result.data[i][0] = exp(m.data[i][0] - maxVal);
        sum += result.data[i][0];
    }

    // 归一化
    for (int i = 0; i < m.rows; i++) {
        result.data[i][0] /= sum;
        // 处理可能的NaN（当sum为0时）
        if (isNaN(result.data[i][0])) {
            result.data[i][0] = 1.0 / m.rows;
        }
    }

    return result;
}

// 修改forward方法中的矩阵运算部分
RNNModel::ForwardCache RNNModel::forward(const std::vector<int>& inputs) {
    ForwardCache cache(layers, hiddenSize, vocabSize);

    for (size_t t = 0; t < inputs.size(); t++) {
        int idx = inputs[t];
        if (idx < 0 || idx >= vocabSize) {
            std::cerr << "无效汉字索引: " << idx << "\n";
            std::exit(1);
        }

        // 输入层独热编码 [vocabSize x 1]
        Matrix x(vocabSize, 1);
        x.data[idx][0] = 1.0;

        // 第一层计算：修复矩阵维度不匹配
        // [hiddenSize x 1] = ([hiddenSize x vocabSize] * [vocabSize x 1]) +
        //                   ([hiddenSize x hiddenSize] * [hiddenSize x 1]) + [hiddenSize x 1]
        Matrix wxhResult = Wxh * x;          // [hiddenSize x 1]
        Matrix whhResult = Whh[0] * cache.h[0];  // [hiddenSize x 1]
        cache.a[0] = wxhResult + whhResult + bh[0];  // 正确的维度相加
        cache.h[0] = activate(cache.a[0]);

        // 深层计算
        for (int l = 1; l < layers; l++) {
            // [hiddenSize x 1] = [hiddenSize x hiddenSize] * [hiddenSize x 1] + [hiddenSize x 1]
            cache.a[l] = Whh[l] * cache.h[l-1] + bh[l];
            cache.h[l] = activate(cache.a[l]);
        }

        // 输出层计算 [vocabSize x 1] = [vocabSize x hiddenSize] * [hiddenSize x 1] + [vocabSize x 1]
        cache.y = Why * cache.h[layers-1] + by;
    }

    return cache;
}

void RNNModel::adamUpdate(Matrix& param, AdamParams& opt, const Matrix& grad, double lr, int t) {
    // 复制梯度用于修改
    Matrix safeGrad = grad;

    // 检查并替换梯度中的NaN
    for (int i = 0; i < safeGrad.rows; i++) {
        for (int j = 0; j < safeGrad.cols; j++) {
            if (isNaN(safeGrad.data[i][j])) {
                safeGrad.data[i][j] = 0.0;  // NaN梯度替换为0
            }
        }
    }

    // 梯度裁剪，防止梯度爆炸
    clipGradients(safeGrad, 5.0);  // 最大范数设为5.0

    for (int i = 0; i < param.rows; i++) {
        for (int j = 0; j < param.cols; j++) {
            // 更新一阶矩估计
            opt.m.data[i][j] = opt.beta1 * opt.m.data[i][j] + (1 - opt.beta1) * safeGrad.data[i][j];
            // 更新二阶矩估计
            opt.v.data[i][j] = opt.beta2 * opt.v.data[i][j] + (1 - opt.beta2) * safeGrad.data[i][j] * safeGrad.data[i][j];

            // 偏差修正
            double m_hat = opt.m.data[i][j] / (1 - pow(opt.beta1, t));
            double v_hat = opt.v.data[i][j] / (1 - pow(opt.beta2, t));

            // 参数更新，添加额外保护防止NaN
            if (!isNaN(m_hat) && !isNaN(v_hat) && v_hat > 0) {
                param.data[i][j] -= lr * m_hat / (sqrt(v_hat) + opt.epsilon);
            }

            // 最后检查参数是否为NaN
            if (isNaN(param.data[i][j])) {
                param.data[i][j] = 0.01;  // 重置为小值
            }
        }
    }
}

void RNNModel::train(const std::vector<int>& sequence, double learningRate, int epoch) {
    if (sequence.size() < 2) return;

    std::vector<int> inputs(sequence.begin(), sequence.end() - 1);
    std::vector<int> targets(sequence.begin() + 1, sequence.end());

    auto cache = forward(inputs);
    int lastTarget = targets.back();
    if (lastTarget < 0 || lastTarget >= vocabSize) return;

    // 输出误差 [vocabSize x 1]
    Matrix dy(vocabSize, 1);
    for (int i = 0; i < vocabSize; i++) {
        dy.data[i][0] = cache.y.data[i][0] - (i == lastTarget ? 1.0 : 0.0);
    }

    // 计算误差项
    std::vector<Matrix> dh(layers, Matrix(hiddenSize, 1));

    // 最后一层隐藏层误差
    Matrix whyT = Why.transpose();  // [hiddenSize x vocabSize]
    dh[layers-1] = whyT * dy;       // [hiddenSize x 1] = [hiddenSize x vocabSize] * [vocabSize x 1]
    dh[layers-1] = dh[layers-1] * activateDerivative(cache.a[layers-1]);

    // 深层误差反向传播
    for (int l = layers-2; l >= 0; l--) {
        Matrix whhT = Whh[l+1].transpose();  // [hiddenSize x hiddenSize]
        dh[l] = whhT * dh[l+1];              // [hiddenSize x 1] = [hiddenSize x hiddenSize] * [hiddenSize x 1]
        dh[l] = dh[l] * activateDerivative(cache.a[l]);
    }

    // 更新权重（确保所有矩阵乘法维度正确）
    Matrix whyGrad = dy * cache.h[layers-1].transpose();  // [vocabSize x hiddenSize]
    adamUpdate(Why, optWhy, whyGrad, learningRate, epoch);

    // 更新第一层权重
    Matrix x(vocabSize, 1);
    x.data[inputs.back()][0] = 1.0;
    Matrix wxhGrad = dh[0] * x.transpose();  // [hiddenSize x vocabSize]
    adamUpdate(Wxh, optWxh, wxhGrad, learningRate, epoch);

    // 更新隐藏层权重
    for (int l = 0; l < layers; l++) {
        Matrix hPrev = (l == 0) ? cache.h[0] : cache.h[l-1];
        Matrix whhGrad = dh[l] * hPrev.transpose();  // [hiddenSize x hiddenSize]
        adamUpdate(Whh[l], optWhh[l], whhGrad, learningRate, epoch);
        adamUpdate(bh[l], optBh[l], dh[l], learningRate, epoch);
    }

    adamUpdate(by, optBy, dy, learningRate, epoch);
}

int RNNModel::predict(const std::vector<int>& inputSeq, bool random, double temperature) {
    auto cache = forward(inputSeq);

    // 应用温度调整概率分布，使用稳定的softmax
    Matrix probs = softmax(cache.y);

    // 温度调整
    for (int i = 0; i < vocabSize; i++) {
        if (probs.data[i][0] <= 0) {
            probs.data[i][0] = 1e-10;  // 防止log(0)
        }
        probs.data[i][0] = pow(probs.data[i][0], 1.0 / temperature);
    }

    // 归一化概率
    double sum = 0.0;
    for (int i = 0; i < vocabSize; i++) {
        sum += probs.data[i][0];
    }

    // 处理sum为0的情况
    if (sum <= 0) {
        for (int i = 0; i < vocabSize; i++) {
            probs.data[i][0] = 1.0 / vocabSize;
        }
        sum = 1.0;
    }

    for (int i = 0; i < vocabSize; i++) {
        probs.data[i][0] /= sum;
        // 最终检查NaN
        if (isNaN(probs.data[i][0])) {
            probs.data[i][0] = 1.0 / vocabSize;
        }
    }

    if (!random) {
        // 选择概率最大的字符
        int maxIdx = 0;
        double maxVal = probs.data[0][0];
        for (int i = 1; i < vocabSize; i++) {
            if (probs.data[i][0] > maxVal) {
                maxVal = probs.data[i][0];
                maxIdx = i;
            }
        }
        return maxIdx;
    } else {
        // 基于概率分布随机选择
        std::random_device rd;
        std::mt19937 gen(rd());
        std::uniform_real_distribution<> dis(0.0, 1.0);
        double r = dis(gen);

        double accum = 0.0;
        for (int i = 0; i < vocabSize; i++) {
            accum += probs.data[i][0];
            if (accum >= r) {
                return i;
            }
        }
        return vocabSize - 1; // fallback
    }
}

// 保持其他函数不变...
bool RNNModel::save(const std::string& filename) {
    std::ofstream fout(filename, std::ios::binary);
    if (!fout) return false;

    fout.write((char*)&vocabSize, sizeof(vocabSize));
    fout.write((char*)&hiddenSize, sizeof(hiddenSize));
    fout.write((char*)&layers, sizeof(layers));
    fout.write((char*)&activationType, sizeof(activationType));

    auto saveMatrix = [&](const Matrix& m) {
        fout.write((char*)&m.rows, sizeof(m.rows));
        fout.write((char*)&m.cols, sizeof(m.cols));
        for (const auto& row : m.data)
            fout.write((char*)row.data(), row.size() * sizeof(double));
    };

    saveMatrix(Wxh);
    for (const auto& m : Whh) saveMatrix(m);
    saveMatrix(Why);
    for (const auto& m : bh) saveMatrix(m);
    saveMatrix(by);

    return true;
}

bool RNNModel::load(const std::string& filename) {
    std::ifstream fin(filename, std::ios::binary);
    if (!fin) return false;

    fin.read((char*)&vocabSize, sizeof(vocabSize));
    fin.read((char*)&hiddenSize, sizeof(hiddenSize));
    fin.read((char*)&layers, sizeof(layers));

    int actType;
    fin.read((char*)&actType, sizeof(actType));
    activationType = static_cast<ActivationType>(actType);

    auto loadMatrix = [&](Matrix& m) {
        int rows, cols;
        fin.read((char*)&rows, sizeof(rows));
        fin.read((char*)&cols, sizeof(cols));
        m = Matrix(rows, cols);
        for (int i = 0; i < rows; i++) {
            m.data[i].resize(cols);
            fin.read((char*)m.data[i].data(), cols * sizeof(double));
        }
    };

    loadMatrix(Wxh);
    Whh.resize(layers);
    for (int i = 0; i < layers; i++) loadMatrix(Whh[i]);
    loadMatrix(Why);
    bh.resize(layers);
    for (int i = 0; i < layers; i++) loadMatrix(bh[i]);
    loadMatrix(by);

    // 重新初始化优化器参数
    optWxh = AdamParams();
    optWhy = AdamParams();
    optWhh.resize(layers);
    optBh.resize(layers);
    optBy = AdamParams();

    return true;
}

void RNNModel::selfLearn(int iterations, int seqLen, double lr) {
    double currentLr = lr;
    int consecutiveErrors = 0;

    for (int i = 0; i < iterations; i++) {
        try {
            std::vector<int> seq;
            for (int j = 0; j < seqLen; j++) {
                seq.push_back(rand() % vocabSize);
            }

            // 每1000次迭代降低一次学习率
            if (i % 1000 == 0 && i > 0) {
                currentLr *= 0.95;  // 5%衰减率
            }

            train(seq, currentLr, i);
            consecutiveErrors = 0;  // 重置错误计数

            // 每5000次迭代输出进度
            if (i % 5000 == 0) {
                printf("📊 训练进度: %.1f%% (迭代 %d/%d)\n",
                       (double)i/iterations*100, i, iterations);
            }
        } catch (const std::exception& e) {
            std::cerr << "❌ 训练步骤失败: " << e.what() << "\n";
            consecutiveErrors++;

            // 如果连续出错，降低学习率
            if (consecutiveErrors >= 5) {
                currentLr *= 0.5;
                std::cerr << "⚠️ 连续错误，降低学习率至: " << currentLr << "\n";
                consecutiveErrors = 0;

                // 如果学习率过小，仍然出错，则终止训练
                if (currentLr < 1e-8) {
                    throw std::runtime_error("学习率已过小但仍出错，无法继续训练");
                }
            }
        }
    }
}
"

rnn_model.h
"
#ifndef AI3700_RNN_MODEL_H
#define AI3700_RNN_MODEL_H
#include "matrix.h"
#include <vector>
#include <string>
#include <random>

// Adam优化器参数结构体
struct AdamParams {
    Matrix m;  // 一阶矩估计
    Matrix v;  // 二阶矩估计
    double beta1;
    double beta2;
    double epsilon;

    AdamParams() : beta1(0.9), beta2(0.999), epsilon(1e-8) {}
};

class RNNModel {
public:
    RNNModel(int vocabSize, int hiddenSize, int layers = 2);
    void train(const std::vector<int>& sequence, double learningRate, int epoch);
    int predict(const std::vector<int>& inputSeq, bool random = false, double temperature = 1.0);
    bool save(const std::string& filename);
    bool load(const std::string& filename);
    void selfLearn(int iterations, int seqLen, double lr);

    // 设置激活函数类型
    enum ActivationType { TANH, RELU, LEAKY_RELU, SIGMOID };
    void setActivation(ActivationType type) { activationType = type; }

private:
    int vocabSize;  // 汉字总数
    int hiddenSize; // 隐藏层大小
    int layers;     // 层数
    ActivationType activationType; // 激活函数类型

    // 权重矩阵
    Matrix Wxh;       // 输入→隐藏 [hiddenSize x vocabSize]
    std::vector<Matrix> Whh;  // 隐藏→隐藏 [hiddenSize x hiddenSize]
    Matrix Why;       // 隐藏→输出 [vocabSize x hiddenSize]
    std::vector<Matrix> bh;   // 隐藏层偏置 [hiddenSize x 1]
    Matrix by;        // 输出层偏置 [vocabSize x 1]

    // Adam优化器参数
    AdamParams optWxh, optWhy;
    std::vector<AdamParams> optWhh, optBh;
    AdamParams optBy;

    // 新增：Xavier初始化方法
    void xavierInit(Matrix& m, int fanIn, int fanOut);
    // 新增：梯度裁剪
    void clipGradient(Matrix& grad, double maxNorm);
    // 新增：检查NaN值
    void checkNaN(const Matrix& m, const std::string& msg);

    struct ForwardCache {
        std::vector<Matrix> h;  // 各层隐藏状态 [hiddenSize x 1]
        std::vector<Matrix> a;  // 各层激活前的值 [hiddenSize x 1]
        Matrix y;               // 输出 [vocabSize x 1]

        ForwardCache(int layers, int hiddenSize, int vocabSize) {
            h.resize(layers, Matrix(hiddenSize, 1));
            a.resize(layers, Matrix(hiddenSize, 1));
            y = Matrix(vocabSize, 1);
        }
    };

    ForwardCache forward(const std::vector<int>& inputs);
    Matrix activate(const Matrix& m);
    Matrix activateDerivative(const Matrix& m);

    // Adam优化更新
    void adamUpdate(Matrix& param, AdamParams& opt, const Matrix& grad, double lr, int t);
};

#endif //AI3700_RNN_MODEL_H
"

start_model.cpp
"
#include "start_model.h"
#include <vector>
#include <string>
#include <queue>
#include <tuple>
#include <algorithm>
#include <iostream>  // 增加调试输出

StartModel::StartModel(HanziEncoder& encoder, int hiddenSize, int layers)
        : encoder(encoder), model(encoder.size(), hiddenSize, layers), contextWindow(5) {}

bool StartModel::loadModel(const std::string& path) {
    if (!model.load(path)) {
        std::cerr << "❌ 模型加载失败: " << path << std::endl;
        return false;
    }
    return true;
}

bool StartModel::saveModel(const std::string& path) {
    // 检查路径是否有效
    if (path.empty()) {
        std::cerr << "❌ 模型路径为空" << std::endl;
        return false;
    }

    if (!model.save(path)) {
        std::cerr << "❌ 模型保存失败: " << path << std::endl;
        // 尝试备选路径
        std::string backupPath = "backup_" + path;
        if (model.save(backupPath)) {
            std::cerr << "⚠️ 已保存到备选路径: " << backupPath << std::endl;
            return true;
        }
        return false;
    }
    return true;
}

// 新增：监控训练过程的辅助函数
void printTrainingProgress(int iteration, int total, double loss) {
    if (iteration % 1000 == 0) {
        double progress = static_cast<double>(iteration) / total * 100;
        printf("📊 训练进度: %.1f%% (迭代 %d/%d), 损失: %.6f\n",
               progress, iteration, total, loss);
    }
}

void StartModel::train(int iterations, double lr) {
    // 针对大隐藏层调整训练策略：减小初始学习率
    double initialLr = lr * 0.5;  // 对于128隐藏层，学习率减半

    try {
        // 分阶段训练，增加损失监控
        for (int i = 0; i < iterations; i++) {
            // 动态调整序列长度，避免内存溢出
            int seqLen = 6 + (i % 3) * 2;  // 6-10之间动态调整

            // 生成训练序列
            std::vector<int> seq;
            for (int j = 0; j < seqLen; j++) {
                seq.push_back(rand() % encoder.size());
            }

            // 训练一步并监控损失（简化版损失计算）
            model.train(seq, initialLr * (1 - i/(double)iterations), i);

            // 每1000次迭代打印一次进度
            if (i % 1000 == 0) {
                printTrainingProgress(i, iterations, 0.0);  // 实际项目中应计算真实损失
            }

            // 定期检查数值稳定性
            if (i % 5000 == 0 && i > 0) {
                std::cout << "🔍 检查模型稳定性..." << std::endl;
                // 生成测试序列验证模型是否正常
                std::vector<int> testSeq = {0, 1, 2, 3};  // 随机选择几个汉字索引
                int pred = model.predict(testSeq, false);
                if (pred < 0 || pred >= encoder.size()) {
                    std::cerr << "⚠️ 检测到异常预测，重置学习率" << std::endl;
                    initialLr *= 0.5;  // 遇到异常时降低学习率
                }
            }
        }
    } catch (const std::exception& e) {
        std::cerr << "❌ 训练过程中发生错误: " << e.what() << std::endl;
        // 尝试保存当前模型状态
        saveModel("emergency_model.bin");
    }
}

std::vector<int> StartModel::strToSeq(const std::string& input) {
    std::vector<int> seq;
    for (size_t i = 0; i < input.size();) {
        unsigned char c = (unsigned char)input[i];
        size_t len = 1;

        // 判断UTF-8字符长度
        if ((c & 0xF0) == 0xE0) len = 3;  // 汉字为3字节UTF-8
        else if ((c & 0xE0) == 0xC0) len = 2;
        else if (c >= 0x80) { i++; continue; }  // 跳过无效字符

        if (i + len > input.size()) break;

        std::string hanzi = input.substr(i, len);
        i += len;

        int code = encoder.encode(hanzi);
        if (code != -1) {
            seq.push_back(code);
        }
    }
    return seq;
}

std::string StartModel::seqToStr(const std::vector<int>& seq) {
    std::string s;
    for (int code : seq) {
        s += encoder.decode(code);
    }
    return s;
}

std::vector<int> StartModel::beamSearch(const std::vector<int>& inputSeq, int length,
                                        int beamWidth, double temperature) {
    // 限制beamWidth大小，避免内存占用过高
    beamWidth = std::min(beamWidth, 5);  // 对于大模型，减小beamWidth

    std::vector<std::pair<std::vector<int>, double>> beams;
    beams.emplace_back(inputSeq, 0.0);

    for (int i = 0; i < length; i++) {
        std::vector<std::pair<std::vector<int>, double>> newBeams;

        for (const auto& beam : beams) {
            const std::vector<int>& seq = beam.first;
            double score = beam.second;

            std::vector<int> context = seq;
            if ((int)context.size() > contextWindow) {
                context = std::vector<int>(context.end() - contextWindow, context.end());
            }

            // 减少候选数量，降低计算量
            std::vector<std::pair<int, double>> candidates;
            int candidateCount = std::min(beamWidth * 2, encoder.size() / 2);
            for (int j = 0; j < candidateCount; j++) {
                int next = model.predict(context, true, temperature);
                candidates.emplace_back(next, -j);
            }

            for (const auto& cand : candidates) {
                std::vector<int> newSeq = seq;
                newSeq.push_back(cand.first);
                newBeams.emplace_back(newSeq, score + cand.second);
            }
        }

        std::sort(newBeams.begin(), newBeams.end(),
                  [](const std::pair<std::vector<int>, double>& a,
                     const std::pair<std::vector<int>, double>& b) {
                      return a.second > b.second;
                  });

        if ((int)newBeams.size() > beamWidth) {
            newBeams.resize(beamWidth);
        }

        beams = newBeams;

        // 防止空光束
        if (beams.empty()) {
            std::cerr << "⚠️ 光束搜索为空，使用原始序列" << std::endl;
            return inputSeq;
        }
    }

    return beams[0].first;
}

std::string StartModel::generateResponse(const std::string& input, int length,
                                         double temperature, bool random) {
    // 限制生成长度，避免内存溢出
    length = std::min(length, 20);  // 对于大模型，减少生成长度

    std::vector<int> inputSeq = strToSeq(input);
    if (inputSeq.empty()) return "未识别到有效汉字";

    try {
        std::vector<int> outputSeq;

        if (length > 10) {
            outputSeq = beamSearch(inputSeq, length, 3, temperature);  // 进一步减小beamWidth
        } else {
            outputSeq = inputSeq;
            std::vector<int> context = inputSeq;

            for (int i = 0; i < length; i++) {
                if ((int)context.size() > contextWindow) {
                    context = std::vector<int>(context.end() - contextWindow, context.end());
                }

                int next = model.predict(context, random, temperature);
                outputSeq.push_back(next);
                context.push_back(next);
            }
        }

        return seqToStr(outputSeq);
    } catch (const std::exception& e) {
        std::cerr << "❌ 生成响应时出错: " << e.what() << std::endl;
        return "生成响应失败，请重试";
    }
}
"

start_model.h
"
#ifndef AI3700_START_MODEL_H
#define AI3700_START_MODEL_H
#include "rnn_model.h"
#include "hanzi_encoder.h"
#include <string>
#include <vector>

class StartModel {
public:
    StartModel(HanziEncoder& encoder, int hiddenSize = 128, int layers = 2);
    bool loadModel(const std::string& path);
    bool saveModel(const std::string& path);
    void train(int iterations = 50000, double lr = 0.001);
    std::string generateResponse(const std::string& input, int length = 20,
                                 double temperature = 0.7, bool random = true);

    // 设置模型参数
    void setContextWindow(int window) { contextWindow = window; }
    void setActivation(RNNModel::ActivationType type) { model.setActivation(type); }

private:
    HanziEncoder& encoder;
    RNNModel model;
    int contextWindow; // 上下文窗口大小

    std::vector<int> strToSeq(const std::string& input);
    std::string seqToStr(const std::vector<int>& seq);

    // 使用beam search提高生成质量
    std::vector<int> beamSearch(const std::vector<int>& inputSeq, int length,
                                int beamWidth = 5, double temperature = 1.0);
};

#endif //AI3700_START_MODEL_H
"